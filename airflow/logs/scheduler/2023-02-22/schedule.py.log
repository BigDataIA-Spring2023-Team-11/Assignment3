[2023-02-22T19:34:23.253+0000] {processor.py:153} INFO - Started process (PID=50) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:34:23.260+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:34:23.264+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:34:23.263+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:34:23.360+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:34:23.353+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:34:23.363+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:34:23.406+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.163 seconds
[2023-02-22T19:34:53.718+0000] {processor.py:153} INFO - Started process (PID=76) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:34:53.728+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:34:53.739+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:34:53.735+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:34:53.905+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:34:53.878+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:34:53.918+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:34:54.078+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.390 seconds
[2023-02-22T19:35:24.530+0000] {processor.py:153} INFO - Started process (PID=97) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:35:24.554+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:35:24.577+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:35:24.576+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:35:24.640+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:35:24.633+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:35:24.642+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:35:24.693+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.184 seconds
[2023-02-22T19:35:59.540+0000] {processor.py:153} INFO - Started process (PID=101) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:35:59.581+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:35:59.611+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:35:59.606+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:35:59.748+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:35:59.726+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:35:59.754+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:35:59.959+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.500 seconds
[2023-02-22T19:36:33.141+0000] {processor.py:153} INFO - Started process (PID=120) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:36:33.370+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:36:33.385+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:36:33.381+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:36:35.395+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:36:35.100+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:36:35.624+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:36:36.261+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 5.246 seconds
[2023-02-22T19:37:07.926+0000] {processor.py:153} INFO - Started process (PID=138) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:37:07.947+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:37:07.972+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:37:07.956+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:37:08.584+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:37:08.534+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:37:08.590+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:37:11.381+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 3.570 seconds
[2023-02-22T19:37:43.194+0000] {processor.py:153} INFO - Started process (PID=149) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:37:43.623+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:37:43.667+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:37:43.646+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:37:44.414+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:37:44.275+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:37:44.451+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:37:46.064+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 3.312 seconds
[2023-02-22T19:38:25.817+0000] {processor.py:153} INFO - Started process (PID=160) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:38:26.074+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:38:26.973+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:38:26.584+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:38:36.766+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:38:36.091+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:38:37.145+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:38:41.546+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 16.479 seconds
[2023-02-22T19:39:17.916+0000] {processor.py:153} INFO - Started process (PID=188) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:39:17.967+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:39:18.221+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:39:18.182+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:39:41.838+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:39:34.894+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:39:47.755+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:39:57.425+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 40.077 seconds
[2023-02-22T19:40:42.198+0000] {processor.py:153} INFO - Started process (PID=213) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:40:42.442+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:40:42.504+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:40:42.494+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:40:43.583+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:40:43.522+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:40:43.597+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:40:48.025+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 8.031 seconds
[2023-02-22T19:41:30.438+0000] {processor.py:153} INFO - Started process (PID=238) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:41:30.607+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:41:30.773+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:41:30.751+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:41:35.619+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:41:34.654+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:41:35.935+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:41:56.836+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 28.048 seconds
[2023-02-22T19:42:42.589+0000] {processor.py:153} INFO - Started process (PID=269) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:42:44.297+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:42:45.754+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:42:45.246+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:42:59.071+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:42:56.883+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:42:59.474+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:43:13.372+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 34.269 seconds
[2023-02-22T19:43:57.606+0000] {processor.py:153} INFO - Started process (PID=303) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:44:00.624+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:44:03.615+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:44:02.075+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:46:16.655+0000] {processor.py:153} INFO - Started process (PID=50) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:46:16.661+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:46:16.662+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:46:16.662+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:46:16.717+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:46:16.714+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:46:16.722+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:46:16.751+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.110 seconds
[2023-02-22T19:46:47.139+0000] {processor.py:153} INFO - Started process (PID=75) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:46:47.141+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:46:47.143+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:46:47.143+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:46:47.171+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:46:47.165+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:46:47.172+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:46:47.207+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.073 seconds
[2023-02-22T19:47:17.547+0000] {processor.py:153} INFO - Started process (PID=112) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:47:17.550+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:47:17.551+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:47:17.551+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:47:17.601+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:47:17.595+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:47:17.603+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:47:17.632+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.092 seconds
[2023-02-22T19:47:47.999+0000] {processor.py:153} INFO - Started process (PID=137) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:47:48.001+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:47:48.003+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:47:48.003+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:47:48.029+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:47:48.025+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:47:48.030+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:47:48.068+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.073 seconds
[2023-02-22T19:48:18.563+0000] {processor.py:153} INFO - Started process (PID=175) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:48:18.566+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:48:18.569+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:48:18.569+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:48:18.590+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:48:18.588+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:48:18.592+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:48:18.618+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.061 seconds
[2023-02-22T19:48:49.387+0000] {processor.py:153} INFO - Started process (PID=201) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:48:49.389+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:48:49.391+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:48:49.391+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:48:49.417+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:48:49.414+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:48:49.418+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:48:49.458+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.082 seconds
[2023-02-22T19:49:19.941+0000] {processor.py:153} INFO - Started process (PID=238) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:49:19.943+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:49:19.945+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:49:19.945+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:49:19.969+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:49:19.965+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:49:19.971+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:49:20.004+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.068 seconds
[2023-02-22T19:49:50.483+0000] {processor.py:153} INFO - Started process (PID=265) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:49:50.485+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:49:50.487+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:49:50.487+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:49:50.515+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:49:50.511+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:49:50.516+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:49:50.567+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.109 seconds
[2023-02-22T19:50:21.224+0000] {processor.py:153} INFO - Started process (PID=303) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:50:21.226+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:50:21.228+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:50:21.227+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:50:21.248+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:50:21.246+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:50:21.250+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:50:21.279+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.061 seconds
[2023-02-22T19:50:51.887+0000] {processor.py:153} INFO - Started process (PID=327) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:50:51.899+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:50:51.908+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:50:51.907+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:50:51.944+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:50:51.939+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 10, in <module>
    'start_date': days_ago(1)
NameError: name 'days_ago' is not defined
[2023-02-22T19:50:51.946+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:50:51.992+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.115 seconds
[2023-02-22T19:51:06.167+0000] {processor.py:153} INFO - Started process (PID=340) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:51:06.170+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:51:06.173+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:51:06.173+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:51:06.309+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:51:06.629+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:51:06.629+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:scrap_metadata
[2023-02-22T19:51:06.638+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:51:06.637+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:scrap_metadata
[2023-02-22T19:51:06.647+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:51:06.647+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:scrap_metadata
[2023-02-22T19:51:06.649+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:51:06.648+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:51:06.677+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:51:06.677+0000] {dag.py:2711} INFO - Creating ORM DAG for scrap_metadata
[2023-02-22T19:51:06.700+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:51:06.699+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-21T00:00:00+00:00, run_after=2023-02-22T00:00:00+00:00
[2023-02-22T19:51:06.715+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.558 seconds
[2023-02-22T19:51:37.138+0000] {processor.py:153} INFO - Started process (PID=377) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:51:37.141+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:51:37.142+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:51:37.142+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:51:37.176+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:51:37.208+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:51:37.208+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:51:37.238+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:51:37.238+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-21T00:00:00+00:00, run_after=2023-02-22T00:00:00+00:00
[2023-02-22T19:51:37.252+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.118 seconds
[2023-02-22T19:52:07.591+0000] {processor.py:153} INFO - Started process (PID=410) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:52:07.594+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:52:07.597+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:52:07.596+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:52:07.646+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:52:07.694+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:52:07.694+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:52:07.728+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:52:07.728+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-21T00:00:00+00:00, run_after=2023-02-22T00:00:00+00:00
[2023-02-22T19:52:07.748+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.162 seconds
[2023-02-22T19:52:38.207+0000] {processor.py:153} INFO - Started process (PID=440) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:52:38.211+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:52:38.213+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:52:38.213+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:52:38.257+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:52:38.296+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:52:38.296+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:52:38.326+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:52:38.326+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-21T00:00:00+00:00, run_after=2023-02-22T00:00:00+00:00
[2023-02-22T19:52:38.343+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.142 seconds
[2023-02-22T19:53:08.975+0000] {processor.py:153} INFO - Started process (PID=465) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:53:08.978+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:53:08.984+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:53:08.984+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:53:09.040+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:53:09.091+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:53:09.091+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:53:09.128+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:53:09.128+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T19:53:09.149+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.180 seconds
[2023-02-22T19:53:39.602+0000] {processor.py:153} INFO - Started process (PID=501) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:53:39.605+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:53:39.607+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:53:39.606+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:53:39.648+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:53:39.695+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:53:39.695+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:53:39.727+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:53:39.726+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T19:53:39.741+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.147 seconds
[2023-02-22T19:54:10.251+0000] {processor.py:153} INFO - Started process (PID=526) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:54:10.255+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:54:10.257+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:54:10.256+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:54:10.300+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:54:10.352+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:54:10.352+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:54:10.389+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:54:10.389+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T19:54:10.407+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.166 seconds
[2023-02-22T19:54:40.938+0000] {processor.py:153} INFO - Started process (PID=563) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:54:40.942+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:54:40.945+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:54:40.944+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:54:40.987+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:54:41.021+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:54:41.021+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:54:41.042+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:54:41.042+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T19:54:41.057+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.126 seconds
[2023-02-22T19:55:11.387+0000] {processor.py:153} INFO - Started process (PID=588) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:55:11.390+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:55:11.392+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:55:11.392+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:55:11.450+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:55:11.522+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:55:11.521+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:55:11.557+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:55:11.556+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T19:55:11.578+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.200 seconds
[2023-02-22T19:55:41.967+0000] {processor.py:153} INFO - Started process (PID=626) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:55:41.969+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:55:41.972+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:55:41.971+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:55:42.007+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:55:42.043+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:55:42.043+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:55:42.068+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:55:42.068+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T19:55:42.085+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.125 seconds
[2023-02-22T19:56:12.483+0000] {processor.py:153} INFO - Started process (PID=652) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:56:12.486+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:56:12.490+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:56:12.490+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:56:12.523+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:56:12.555+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:56:12.555+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:56:12.578+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:56:12.578+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T19:56:12.591+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.114 seconds
[2023-02-22T19:56:43.011+0000] {processor.py:153} INFO - Started process (PID=689) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:56:43.014+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:56:43.016+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:56:43.016+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:56:43.052+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:56:43.082+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:56:43.082+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:56:43.111+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:56:43.111+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T19:56:43.124+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.119 seconds
[2023-02-22T19:57:13.437+0000] {processor.py:153} INFO - Started process (PID=714) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:57:13.441+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:57:13.442+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:57:13.442+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:57:13.488+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:57:13.530+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:57:13.530+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:57:13.565+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:57:13.564+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T19:57:13.585+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.155 seconds
[2023-02-22T19:57:43.739+0000] {processor.py:153} INFO - Started process (PID=751) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:57:43.742+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:57:43.744+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:57:43.744+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:57:43.809+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:57:43.856+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:57:43.856+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:57:43.891+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:57:43.890+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T19:57:43.908+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.179 seconds
[2023-02-22T19:58:14.323+0000] {processor.py:153} INFO - Started process (PID=776) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:58:14.327+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:58:14.328+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:58:14.328+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:58:14.368+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:58:14.400+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:58:14.400+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:58:14.427+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:58:14.427+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T19:58:14.442+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.129 seconds
[2023-02-22T19:58:44.764+0000] {processor.py:153} INFO - Started process (PID=813) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:58:44.767+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:58:44.769+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:58:44.769+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:58:44.809+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:58:44.841+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:58:44.841+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:58:44.872+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:58:44.872+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T19:58:44.888+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.130 seconds
[2023-02-22T19:59:15.203+0000] {processor.py:153} INFO - Started process (PID=837) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:59:15.210+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:59:15.216+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:59:15.216+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:59:15.311+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:59:15.384+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:59:15.384+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:59:15.436+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:59:15.436+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T19:59:15.457+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.269 seconds
[2023-02-22T19:59:45.548+0000] {processor.py:153} INFO - Started process (PID=874) to work on /opt/airflow/dags/schedule.py
[2023-02-22T19:59:45.551+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T19:59:45.553+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:59:45.553+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T19:59:45.591+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T19:59:45.629+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:59:45.629+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T19:59:45.653+0000] {logging_mixin.py:137} INFO - [2023-02-22T19:59:45.652+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T19:59:45.675+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.133 seconds
[2023-02-22T20:00:15.963+0000] {processor.py:153} INFO - Started process (PID=907) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:00:15.966+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:00:15.969+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:00:15.968+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:00:16.018+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:00:16.074+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:00:16.074+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:00:16.118+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:00:16.117+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:00:16.144+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.188 seconds
[2023-02-22T20:00:46.384+0000] {processor.py:153} INFO - Started process (PID=934) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:00:46.388+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:00:46.390+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:00:46.390+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:00:46.429+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:00:46.493+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:00:46.492+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:00:46.544+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:00:46.544+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:00:46.559+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.183 seconds
[2023-02-22T20:01:16.925+0000] {processor.py:153} INFO - Started process (PID=972) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:01:16.928+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:01:16.929+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:01:16.929+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:01:16.963+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:01:16.994+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:01:16.994+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:01:17.015+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:01:17.015+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:01:17.031+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.111 seconds
[2023-02-22T20:01:47.497+0000] {processor.py:153} INFO - Started process (PID=998) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:01:47.501+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:01:47.503+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:01:47.503+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:01:47.551+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:01:47.588+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:01:47.588+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:01:47.615+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:01:47.615+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:01:47.632+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.144 seconds
[2023-02-22T20:02:17.922+0000] {processor.py:153} INFO - Started process (PID=1035) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:02:17.925+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:02:17.932+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:02:17.931+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:02:17.969+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:02:18.012+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:02:18.012+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:02:18.045+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:02:18.044+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:02:18.062+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.149 seconds
[2023-02-22T20:02:48.318+0000] {processor.py:153} INFO - Started process (PID=1061) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:02:48.321+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:02:48.322+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:02:48.322+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:02:48.359+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:02:48.399+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:02:48.399+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:02:48.422+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:02:48.422+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:02:48.436+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.125 seconds
[2023-02-22T20:03:18.722+0000] {processor.py:153} INFO - Started process (PID=1097) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:03:18.725+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:03:18.727+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:03:18.727+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:03:18.762+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:03:18.793+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:03:18.793+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:03:18.813+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:03:18.813+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:03:18.834+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.122 seconds
[2023-02-22T20:03:49.085+0000] {processor.py:153} INFO - Started process (PID=1122) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:03:49.089+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:03:49.090+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:03:49.090+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:03:49.141+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:03:49.179+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:03:49.179+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:03:49.210+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:03:49.210+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:03:49.230+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.154 seconds
[2023-02-22T20:04:19.502+0000] {processor.py:153} INFO - Started process (PID=1159) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:04:19.505+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:04:19.506+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:04:19.506+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:04:19.539+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:04:19.574+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:04:19.573+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:04:19.598+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:04:19.598+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:04:19.617+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.122 seconds
[2023-02-22T20:04:49.976+0000] {processor.py:153} INFO - Started process (PID=1191) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:04:49.979+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:04:49.981+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:04:49.981+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:04:50.017+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:04:50.060+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:04:50.060+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:04:50.099+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:04:50.099+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:04:50.117+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.149 seconds
[2023-02-22T20:05:20.392+0000] {processor.py:153} INFO - Started process (PID=1222) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:05:20.395+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:05:20.397+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:05:20.396+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:05:20.444+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:05:20.493+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:05:20.493+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:05:20.527+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:05:20.527+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:05:20.553+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.175 seconds
[2023-02-22T20:05:51.035+0000] {processor.py:153} INFO - Started process (PID=1254) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:05:51.040+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:05:51.043+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:05:51.043+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:05:51.097+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:05:51.151+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:05:51.151+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:05:51.190+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:05:51.190+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:05:51.210+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.181 seconds
[2023-02-22T20:06:21.933+0000] {processor.py:153} INFO - Started process (PID=1284) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:06:22.207+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:06:27.826+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:06:27.372+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:06:28.400+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:06:28.586+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:06:28.585+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:06:28.660+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:06:28.660+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:06:28.691+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 6.849 seconds
[2023-02-22T20:17:13.090+0000] {processor.py:153} INFO - Started process (PID=1309) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:17:13.105+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:17:13.121+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:17:13.121+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:17:14.186+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:17:14.530+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:17:14.529+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:17:14.754+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:17:14.753+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:17:15.022+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 2.149 seconds
[2023-02-22T20:17:45.399+0000] {processor.py:153} INFO - Started process (PID=1334) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:17:45.406+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:17:45.408+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:17:45.408+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:17:45.459+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:17:45.512+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:17:45.512+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:17:45.554+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:17:45.554+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:17:45.575+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.182 seconds
[2023-02-22T20:18:16.206+0000] {processor.py:153} INFO - Started process (PID=1359) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:18:16.214+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:18:16.218+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:18:16.218+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:18:16.285+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:18:16.351+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:18:16.351+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:18:16.421+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:18:16.420+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:18:16.448+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.250 seconds
[2023-02-22T20:18:46.792+0000] {processor.py:153} INFO - Started process (PID=1395) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:18:46.795+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:18:46.797+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:18:46.797+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:18:46.849+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:18:46.900+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:18:46.900+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:18:46.943+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:18:46.943+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:18:46.961+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.178 seconds
[2023-02-22T20:18:47.857+0000] {processor.py:153} INFO - Started process (PID=1396) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:18:47.867+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:18:47.869+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:18:47.869+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:18:47.893+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:18:47.882+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 35
    )
    ^
SyntaxError: invalid syntax
[2023-02-22T20:18:47.895+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:18:47.922+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.078 seconds
[2023-02-22T20:18:59.116+0000] {processor.py:153} INFO - Started process (PID=1409) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:18:59.118+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:18:59.123+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:18:59.123+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:18:59.183+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:18:59.232+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:18:59.232+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:18:59.270+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:18:59.270+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:18:59.291+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.179 seconds
[2023-02-22T20:19:29.644+0000] {processor.py:153} INFO - Started process (PID=1434) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:19:29.648+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:19:29.652+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:19:29.650+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:19:29.725+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:19:29.787+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:19:29.787+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:19:29.828+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:19:29.828+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:19:29.852+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.221 seconds
[2023-02-22T20:20:00.079+0000] {processor.py:153} INFO - Started process (PID=1472) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:20:00.082+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:20:00.084+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:20:00.084+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:20:00.123+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:20:00.157+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:20:00.157+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:20:00.179+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:20:00.178+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:20:00.195+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.120 seconds
[2023-02-22T20:20:30.550+0000] {processor.py:153} INFO - Started process (PID=1497) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:20:30.553+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:20:30.554+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:20:30.554+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:20:30.606+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:20:30.650+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:20:30.650+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:20:30.680+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:20:30.680+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:20:30.694+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.149 seconds
[2023-02-22T20:21:01.014+0000] {processor.py:153} INFO - Started process (PID=1534) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:21:01.018+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:21:01.020+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:21:01.019+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:21:01.061+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:21:01.105+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:21:01.104+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:21:01.136+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:21:01.136+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:21:01.154+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.155 seconds
[2023-02-22T20:21:31.724+0000] {processor.py:153} INFO - Started process (PID=1559) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:21:31.728+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:21:31.730+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:21:31.729+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:21:31.781+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:21:31.834+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:21:31.833+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:21:31.881+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:21:31.880+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:21:31.904+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.190 seconds
[2023-02-22T20:22:02.238+0000] {processor.py:153} INFO - Started process (PID=1596) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:22:02.242+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:22:02.244+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:22:02.244+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:22:02.298+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:22:02.350+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:22:02.350+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:22:02.408+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:22:02.407+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:22:02.448+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.216 seconds
[2023-02-22T20:22:32.807+0000] {processor.py:153} INFO - Started process (PID=1621) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:22:32.811+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:22:32.812+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:22:32.812+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:22:32.857+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:22:32.899+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:22:32.899+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:22:32.927+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:22:32.927+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:22:32.943+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.143 seconds
[2023-02-22T20:23:03.378+0000] {processor.py:153} INFO - Started process (PID=1656) to work on /opt/airflow/dags/schedule.py
[2023-02-22T20:23:03.382+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T20:23:03.385+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:23:03.384+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T20:23:03.508+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T20:23:03.592+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:23:03.592+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2023-02-22T20:23:03.669+0000] {logging_mixin.py:137} INFO - [2023-02-22T20:23:03.669+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T20:23:03.724+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.364 seconds
[2023-02-22T21:09:37.303+0000] {processor.py:153} INFO - Started process (PID=45) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:09:37.313+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:09:37.322+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:09:37.322+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:09:37.393+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:09:37.388+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 8, in <module>
    from great_expectations_provider.operators.great_expectations import GreatExpectationsOperator
ModuleNotFoundError: No module named 'great_expectations_provider'
[2023-02-22T21:09:37.395+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:09:37.442+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.151 seconds
[2023-02-22T21:10:08.174+0000] {processor.py:153} INFO - Started process (PID=75) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:10:08.178+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:10:08.181+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:10:08.180+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:10:08.276+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:10:08.267+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 8, in <module>
    from great_expectations_provider.operators.great_expectations import GreatExpectationsOperator
ModuleNotFoundError: No module named 'great_expectations_provider'
[2023-02-22T21:10:08.284+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:10:08.344+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.185 seconds
[2023-02-22T21:10:38.842+0000] {processor.py:153} INFO - Started process (PID=101) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:10:38.844+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:10:38.846+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:10:38.846+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:10:38.865+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:10:38.862+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 8, in <module>
    from great_expectations_provider.operators.great_expectations import GreatExpectationsOperator
ModuleNotFoundError: No module named 'great_expectations_provider'
[2023-02-22T21:10:38.866+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:10:38.886+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.050 seconds
[2023-02-22T21:11:09.461+0000] {processor.py:153} INFO - Started process (PID=133) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:11:09.468+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:11:09.471+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:11:09.471+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:11:09.508+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:11:09.500+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 8, in <module>
    from great_expectations_provider.operators.great_expectations import GreatExpectationsOperator
ModuleNotFoundError: No module named 'great_expectations_provider'
[2023-02-22T21:11:09.513+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:11:09.543+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.093 seconds
[2023-02-22T21:11:25.968+0000] {processor.py:153} INFO - Started process (PID=150) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:11:25.971+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:11:25.973+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:11:25.972+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:11:26.076+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:11:26.068+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 66, in <module>
    t4 >> t5 # Defining the task dependencies
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T21:11:26.078+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:11:26.119+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.156 seconds
[2023-02-22T21:11:56.524+0000] {processor.py:153} INFO - Started process (PID=173) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:11:56.531+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:11:56.533+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:11:56.532+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:11:56.577+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:11:56.574+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 66, in <module>
    t4 >> t5 # Defining the task dependencies
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T21:11:56.578+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:11:56.624+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.105 seconds
[2023-02-22T21:12:27.017+0000] {processor.py:153} INFO - Started process (PID=211) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:12:27.019+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:12:27.021+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:27.021+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:12:27.052+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:27.049+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 66, in <module>
    t4 >> t5 # Defining the task dependencies
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T21:12:27.054+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:12:27.078+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.066 seconds
[2023-02-22T21:12:36.198+0000] {processor.py:153} INFO - Started process (PID=224) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:12:36.201+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:12:36.202+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:36.202+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:12:36.276+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:12:36.508+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:36.508+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:db_to_csv
[2023-02-22T21:12:36.514+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:36.514+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:db_to_csv
[2023-02-22T21:12:36.519+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:36.519+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:db_to_csv
[2023-02-22T21:12:36.526+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:36.526+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:populate_db
[2023-02-22T21:12:36.530+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:36.530+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:populate_db
[2023-02-22T21:12:36.534+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:36.534+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:populate_db
[2023-02-22T21:12:36.537+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:36.537+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:12:36.550+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:36.549+0000] {dag.py:2711} INFO - Creating ORM DAG for populate_db
[2023-02-22T21:12:36.551+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:36.551+0000] {dag.py:2711} INFO - Creating ORM DAG for db_to_csv
[2023-02-22T21:12:36.565+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:36.565+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:12:36.566+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:36.566+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:12:36.570+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:36.570+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:12:36.589+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.397 seconds
[2023-02-22T21:12:37.243+0000] {processor.py:153} INFO - Started process (PID=225) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:12:37.246+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:12:37.247+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:37.247+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:12:37.279+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:12:37.301+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:37.301+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:12:37.318+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:37.318+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:12:37.322+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:37.322+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:12:37.324+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:12:37.324+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:12:37.336+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.098 seconds
[2023-02-22T21:13:07.781+0000] {processor.py:153} INFO - Started process (PID=250) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:13:07.784+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:13:07.788+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:13:07.788+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:13:07.833+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:13:07.881+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:13:07.881+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:13:07.909+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:13:07.909+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:13:07.916+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:13:07.915+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:13:07.921+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:13:07.920+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:13:07.936+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.162 seconds
[2023-02-22T21:13:38.256+0000] {processor.py:153} INFO - Started process (PID=287) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:13:38.259+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:13:38.261+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:13:38.261+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:13:38.292+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:13:38.336+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:13:38.336+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:13:38.367+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:13:38.367+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:13:38.371+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:13:38.371+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:13:38.374+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:13:38.374+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:13:38.389+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.140 seconds
[2023-02-22T21:14:08.850+0000] {processor.py:153} INFO - Started process (PID=312) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:14:08.854+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:14:08.856+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:14:08.856+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:14:08.897+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:14:08.931+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:14:08.931+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:14:08.950+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:14:08.949+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:14:08.953+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:14:08.953+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:14:08.955+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:14:08.955+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:14:08.969+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.124 seconds
[2023-02-22T21:14:39.618+0000] {processor.py:153} INFO - Started process (PID=346) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:14:39.622+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:14:39.626+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:14:39.626+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:14:39.679+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:14:39.739+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:14:39.739+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:14:39.800+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:14:39.800+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:14:39.807+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:14:39.807+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:14:39.812+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:14:39.812+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:14:39.838+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.226 seconds
[2023-02-22T21:15:10.276+0000] {processor.py:153} INFO - Started process (PID=372) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:15:10.278+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:15:10.280+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:15:10.280+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:15:10.320+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:15:10.362+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:15:10.362+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:15:10.404+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:15:10.404+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:15:10.408+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:15:10.408+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:15:10.411+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:15:10.411+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:15:10.470+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.198 seconds
[2023-02-22T21:15:40.707+0000] {processor.py:153} INFO - Started process (PID=397) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:15:40.710+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:15:40.713+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:15:40.712+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:15:40.762+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:15:40.818+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:15:40.817+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:15:40.870+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:15:40.869+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:15:40.874+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:15:40.874+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:15:40.878+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:15:40.878+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:15:40.896+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.193 seconds
[2023-02-22T21:16:11.300+0000] {processor.py:153} INFO - Started process (PID=435) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:16:11.306+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:16:11.309+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:16:11.308+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:16:11.361+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:16:11.544+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:16:11.544+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:16:11.621+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:16:11.621+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:16:11.632+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:16:11.632+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:16:11.637+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:16:11.637+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:16:11.657+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.363 seconds
[2023-02-22T21:16:41.763+0000] {processor.py:153} INFO - Started process (PID=459) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:16:41.766+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:16:41.767+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:16:41.767+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:16:41.821+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:16:41.875+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:16:41.875+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:16:41.914+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:16:41.914+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:16:41.920+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:16:41.919+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:16:41.923+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:16:41.923+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:16:41.957+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.198 seconds
[2023-02-22T21:17:12.261+0000] {processor.py:153} INFO - Started process (PID=496) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:17:12.264+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:17:12.265+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:17:12.265+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:17:12.311+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:17:12.345+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:17:12.345+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:17:12.370+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:17:12.370+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:17:12.373+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:17:12.373+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:17:12.375+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:17:12.375+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:17:12.392+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.137 seconds
[2023-02-22T21:17:42.733+0000] {processor.py:153} INFO - Started process (PID=521) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:17:42.736+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:17:42.738+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:17:42.737+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:17:42.784+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:17:42.854+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:17:42.854+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:17:42.895+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:17:42.895+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:17:42.902+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:17:42.902+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:17:42.912+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:17:42.912+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:17:42.937+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.208 seconds
[2023-02-22T21:18:13.170+0000] {processor.py:153} INFO - Started process (PID=558) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:18:13.173+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:18:13.174+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:18:13.174+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:18:13.213+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:18:13.244+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:18:13.244+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:18:13.267+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:18:13.267+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:18:13.272+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:18:13.272+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:18:13.274+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:18:13.274+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:18:13.286+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.121 seconds
[2023-02-22T21:18:43.642+0000] {processor.py:153} INFO - Started process (PID=583) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:18:43.649+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:18:43.652+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:18:43.651+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:18:43.698+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:18:43.734+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:18:43.734+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:18:43.757+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:18:43.757+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:18:43.761+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:18:43.761+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:18:43.764+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:18:43.763+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:18:43.782+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.150 seconds
[2023-02-22T21:19:14.078+0000] {processor.py:153} INFO - Started process (PID=619) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:19:14.081+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:19:14.083+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:19:14.083+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:19:14.118+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:19:14.161+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:19:14.161+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:19:14.182+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:19:14.182+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:19:14.185+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:19:14.185+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:19:14.188+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:19:14.188+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:19:14.199+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.126 seconds
[2023-02-22T21:19:44.560+0000] {processor.py:153} INFO - Started process (PID=644) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:19:44.562+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:19:44.564+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:19:44.564+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:19:44.611+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:19:44.645+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:19:44.645+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:19:44.670+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:19:44.669+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:19:44.673+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:19:44.673+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:19:44.675+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:19:44.675+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:19:44.687+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.130 seconds
[2023-02-22T21:20:14.894+0000] {processor.py:153} INFO - Started process (PID=681) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:20:14.897+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:20:14.900+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:20:14.900+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:20:14.957+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:20:15.019+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:20:15.019+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:20:15.058+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:20:15.058+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:20:15.062+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:20:15.061+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:20:15.065+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:20:15.065+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:20:15.078+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.193 seconds
[2023-02-22T21:20:45.950+0000] {processor.py:153} INFO - Started process (PID=706) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:20:45.954+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:20:45.958+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:20:45.957+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:20:46.017+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:20:46.068+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:20:46.068+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:20:46.112+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:20:46.112+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:20:46.116+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:20:46.116+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:20:46.119+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:20:46.119+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:20:46.132+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.192 seconds
[2023-02-22T21:21:16.888+0000] {processor.py:153} INFO - Started process (PID=743) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:21:16.891+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:21:16.895+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:21:16.895+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:21:16.933+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:21:16.980+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:21:16.980+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:21:17.014+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:21:17.014+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:21:17.018+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:21:17.018+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:21:17.021+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:21:17.021+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:21:17.033+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.152 seconds
[2023-02-22T21:21:47.249+0000] {processor.py:153} INFO - Started process (PID=768) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:21:47.254+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:21:47.257+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:21:47.257+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:21:47.339+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:21:47.404+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:21:47.404+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:21:47.451+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:21:47.451+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:21:47.456+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:21:47.456+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:21:47.459+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:21:47.459+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:21:47.479+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.241 seconds
[2023-02-22T21:22:17.860+0000] {processor.py:153} INFO - Started process (PID=805) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:22:17.871+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:22:17.873+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:22:17.873+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:22:17.918+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:22:17.963+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:22:17.963+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:22:17.989+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:22:17.989+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:22:17.994+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:22:17.994+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:22:17.996+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:22:17.996+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:22:18.008+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.157 seconds
[2023-02-22T21:22:48.450+0000] {processor.py:153} INFO - Started process (PID=829) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:22:48.452+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:22:48.454+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:22:48.454+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:22:48.500+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:22:48.543+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:22:48.543+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:22:48.573+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:22:48.573+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:22:48.579+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:22:48.579+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:22:48.582+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:22:48.582+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:22:48.594+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.149 seconds
[2023-02-22T21:23:19.422+0000] {processor.py:153} INFO - Started process (PID=866) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:23:19.430+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:23:19.433+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:23:19.433+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:23:19.478+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:23:19.516+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:23:19.516+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:23:19.544+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:23:19.544+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:23:19.548+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:23:19.548+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:23:19.552+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:23:19.552+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:23:19.569+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.153 seconds
[2023-02-22T21:23:50.349+0000] {processor.py:153} INFO - Started process (PID=891) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:23:50.354+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:23:50.356+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:23:50.356+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:23:50.408+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:23:50.461+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:23:50.461+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:23:50.494+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:23:50.494+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:23:50.498+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:23:50.498+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:23:50.506+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:23:50.506+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:23:50.523+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.179 seconds
[2023-02-22T21:24:21.240+0000] {processor.py:153} INFO - Started process (PID=928) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:24:21.243+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:24:21.248+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:24:21.248+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:24:21.281+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:24:21.322+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:24:21.322+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:24:21.343+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:24:21.343+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:24:21.346+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:24:21.346+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:24:21.349+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:24:21.349+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:24:21.361+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.127 seconds
[2023-02-22T21:24:51.882+0000] {processor.py:153} INFO - Started process (PID=953) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:24:51.888+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:24:51.895+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:24:51.894+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:24:51.980+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:24:52.033+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:24:52.033+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:24:52.075+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:24:52.075+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:24:52.083+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:24:52.083+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:24:52.087+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:24:52.087+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:24:52.102+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.231 seconds
[2023-02-22T21:25:22.585+0000] {processor.py:153} INFO - Started process (PID=990) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:25:22.588+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:25:22.590+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:25:22.590+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:25:22.628+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:25:22.666+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:25:22.666+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:25:22.686+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:25:22.685+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:25:22.690+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:25:22.690+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:25:22.695+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:25:22.695+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:25:22.707+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.129 seconds
[2023-02-22T21:25:53.111+0000] {processor.py:153} INFO - Started process (PID=1015) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:25:53.113+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:25:53.115+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:25:53.114+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:25:53.166+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:25:53.223+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:25:53.223+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:25:53.286+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:25:53.286+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:25:53.291+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:25:53.291+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:25:53.294+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:25:53.294+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:25:53.309+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.205 seconds
[2023-02-22T21:26:23.492+0000] {processor.py:153} INFO - Started process (PID=1054) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:26:23.497+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:26:23.498+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:26:23.498+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:26:23.542+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:26:23.597+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:26:23.596+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:26:23.618+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:26:23.618+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:26:23.621+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:26:23.621+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:26:23.623+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:26:23.623+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:26:23.634+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.150 seconds
[2023-02-22T21:26:54.214+0000] {processor.py:153} INFO - Started process (PID=1079) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:26:54.219+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:26:54.221+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:26:54.221+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:26:54.273+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:26:54.328+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:26:54.328+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:26:54.370+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:26:54.370+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:26:54.376+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:26:54.376+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:26:54.379+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:26:54.379+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:26:54.402+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.197 seconds
[2023-02-22T21:27:24.718+0000] {processor.py:153} INFO - Started process (PID=1118) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:27:24.721+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:27:24.723+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:27:24.723+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:27:24.778+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:27:24.841+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:27:24.841+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:27:24.875+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:27:24.875+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:27:24.880+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:27:24.879+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:27:24.884+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:27:24.884+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:27:24.896+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.184 seconds
[2023-02-22T21:27:55.243+0000] {processor.py:153} INFO - Started process (PID=1142) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:27:55.247+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:27:55.249+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:27:55.249+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:27:55.300+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:27:55.355+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:27:55.355+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:27:55.385+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:27:55.385+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:27:55.389+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:27:55.389+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:27:55.392+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:27:55.392+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:27:55.412+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.176 seconds
[2023-02-22T21:28:25.765+0000] {processor.py:153} INFO - Started process (PID=1179) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:28:25.772+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:28:25.775+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:28:25.775+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:28:25.818+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:28:25.869+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:28:25.869+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:28:25.895+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:28:25.895+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:28:25.899+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:28:25.899+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:28:25.902+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:28:25.902+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:28:25.917+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.161 seconds
[2023-02-22T21:28:56.185+0000] {processor.py:153} INFO - Started process (PID=1204) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:28:56.187+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:28:56.189+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:28:56.189+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:28:56.249+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:28:56.307+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:28:56.307+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:28:56.363+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:28:56.363+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:28:56.372+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:28:56.371+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:28:56.375+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:28:56.375+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:28:56.394+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.217 seconds
[2023-02-22T21:29:26.659+0000] {processor.py:153} INFO - Started process (PID=1241) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:29:26.662+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:29:26.664+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:29:26.663+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:29:26.701+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:29:26.737+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:29:26.737+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:29:26.758+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:29:26.758+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:29:26.762+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:29:26.762+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:29:26.765+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:29:26.765+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:29:26.780+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.126 seconds
[2023-02-22T21:29:56.900+0000] {processor.py:153} INFO - Started process (PID=1266) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:29:56.904+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:29:56.908+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:29:56.908+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:29:56.951+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:29:57.005+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:29:57.005+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:29:57.038+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:29:57.038+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:29:57.042+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:29:57.042+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:29:57.045+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:29:57.045+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:29:57.060+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.166 seconds
[2023-02-22T21:30:27.367+0000] {processor.py:153} INFO - Started process (PID=1302) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:30:27.370+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:30:27.373+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:30:27.372+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:30:27.412+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:30:27.465+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:30:27.464+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:30:27.502+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:30:27.502+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:30:27.508+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:30:27.508+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:30:27.511+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:30:27.511+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:30:27.528+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.172 seconds
[2023-02-22T21:30:58.376+0000] {processor.py:153} INFO - Started process (PID=1327) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:30:58.382+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:30:58.385+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:30:58.385+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:30:58.432+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:30:58.474+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:30:58.474+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:30:58.506+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:30:58.506+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:30:58.509+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:30:58.509+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:30:58.512+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:30:58.512+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:30:58.527+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.157 seconds
[2023-02-22T21:31:28.869+0000] {processor.py:153} INFO - Started process (PID=1364) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:31:28.873+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:31:28.877+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:31:28.876+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:31:28.924+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:31:28.967+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:31:28.967+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:31:28.998+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:31:28.997+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:31:29.002+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:31:29.001+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:31:29.005+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:31:29.004+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:31:29.018+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.156 seconds
[2023-02-22T21:31:59.461+0000] {processor.py:153} INFO - Started process (PID=1389) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:31:59.463+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:31:59.464+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:31:59.464+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:31:59.494+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:31:59.533+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:31:59.533+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:31:59.559+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:31:59.559+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:31:59.563+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:31:59.563+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:31:59.566+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:31:59.566+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:31:59.583+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.127 seconds
[2023-02-22T21:32:30.180+0000] {processor.py:153} INFO - Started process (PID=1425) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:32:30.190+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:32:30.192+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:32:30.192+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:32:30.227+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:32:30.268+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:32:30.268+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:32:30.300+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:32:30.300+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:32:30.305+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:32:30.304+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:32:30.308+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:32:30.308+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:32:30.325+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.151 seconds
[2023-02-22T21:33:00.759+0000] {processor.py:153} INFO - Started process (PID=1449) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:33:00.764+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:33:00.766+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:33:00.766+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:33:00.834+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:33:00.887+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:33:00.887+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:33:00.918+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:33:00.918+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:33:00.922+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:33:00.922+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:33:00.928+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:33:00.928+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:33:00.941+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.191 seconds
[2023-02-22T21:33:31.266+0000] {processor.py:153} INFO - Started process (PID=1486) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:33:31.268+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:33:31.270+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:33:31.269+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:33:31.296+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:33:31.327+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:33:31.327+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:33:31.349+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:33:31.349+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:33:31.356+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:33:31.356+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:33:31.358+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:33:31.358+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:33:31.373+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.111 seconds
[2023-02-22T21:34:01.758+0000] {processor.py:153} INFO - Started process (PID=1511) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:34:01.766+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:34:01.769+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:34:01.769+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:34:01.842+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:34:01.892+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:34:01.892+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:34:01.915+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:34:01.915+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:34:01.921+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:34:01.921+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:34:01.924+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:34:01.924+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:34:01.935+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.185 seconds
[2023-02-22T21:34:32.339+0000] {processor.py:153} INFO - Started process (PID=1548) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:34:32.346+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:34:32.350+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:34:32.350+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:34:32.406+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:34:32.448+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:34:32.448+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:34:32.477+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:34:32.476+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:34:32.482+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:34:32.482+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:34:32.487+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:34:32.486+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:34:32.524+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.190 seconds
[2023-02-22T21:35:03.045+0000] {processor.py:153} INFO - Started process (PID=1573) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:35:03.048+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:35:03.051+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:35:03.051+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:35:03.100+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:35:03.158+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:35:03.156+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:35:03.185+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:35:03.185+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:35:03.191+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:35:03.190+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:35:03.195+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:35:03.195+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:35:03.215+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.182 seconds
[2023-02-22T21:35:33.492+0000] {processor.py:153} INFO - Started process (PID=1612) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:35:33.499+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:35:33.501+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:35:33.501+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:35:33.536+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:35:33.586+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:35:33.586+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:35:33.609+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:35:33.609+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:35:33.613+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:35:33.613+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:35:33.615+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:35:33.615+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:35:33.634+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.150 seconds
[2023-02-22T21:36:04.053+0000] {processor.py:153} INFO - Started process (PID=1637) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:36:04.056+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:36:04.059+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:36:04.059+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:36:04.106+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:36:04.164+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:36:04.164+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:36:04.199+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:36:04.199+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:36:04.204+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:36:04.204+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:36:04.210+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:36:04.210+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:36:04.227+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.180 seconds
[2023-02-22T21:36:34.500+0000] {processor.py:153} INFO - Started process (PID=1675) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:36:34.504+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:36:34.507+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:36:34.507+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:36:34.544+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:36:34.586+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:36:34.586+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:36:34.611+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:36:34.611+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:36:34.615+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:36:34.615+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:36:34.619+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:36:34.619+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:36:34.637+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.143 seconds
[2023-02-22T21:37:05.158+0000] {processor.py:153} INFO - Started process (PID=1701) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:37:05.162+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:37:05.164+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:37:05.164+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:37:05.207+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:37:05.259+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:37:05.259+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T21:37:05.318+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:37:05.318+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T21:37:05.324+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:37:05.324+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T21:37:05.326+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:37:05.326+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T21:37:05.344+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.199 seconds
[2023-02-22T21:37:07.259+0000] {processor.py:153} INFO - Started process (PID=1713) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:37:07.267+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:37:07.270+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:37:07.270+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:37:07.385+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:37:07.367+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 54, in <module>
    bash_command = 'python3 aws_geos.py',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-02-22T21:37:07.388+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:37:07.445+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.195 seconds
[2023-02-22T21:37:37.914+0000] {processor.py:153} INFO - Started process (PID=1737) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:37:37.916+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:37:37.917+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:37:37.917+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:37:37.962+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:37:37.955+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 54, in <module>
    bash_command = 'python3 aws_geos.py',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-02-22T21:37:37.963+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:37:37.990+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.083 seconds
[2023-02-22T21:38:08.463+0000] {processor.py:153} INFO - Started process (PID=1770) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:38:08.465+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:38:08.467+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:38:08.467+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:38:08.503+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:38:08.499+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 54, in <module>
    bash_command = 'python3 aws_geos.py',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-02-22T21:38:08.506+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:38:08.531+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.072 seconds
[2023-02-22T21:38:38.978+0000] {processor.py:153} INFO - Started process (PID=1798) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:38:38.980+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:38:38.982+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:38:38.982+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:38:39.018+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:38:39.013+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 54, in <module>
    bash_command = 'python3 aws_geos.py',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-02-22T21:38:39.019+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:38:39.044+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.072 seconds
[2023-02-22T21:39:10.079+0000] {processor.py:153} INFO - Started process (PID=1824) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:39:10.085+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:39:10.087+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:39:10.087+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:39:10.142+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:39:10.136+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 54, in <module>
    bash_command = 'python3 aws_geos.py',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-02-22T21:39:10.145+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:39:10.189+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.116 seconds
[2023-02-22T21:39:41.161+0000] {processor.py:153} INFO - Started process (PID=1860) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:39:41.166+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:39:41.169+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:39:41.169+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:39:41.224+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:39:41.220+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 54, in <module>
    bash_command = 'python3 aws_geos.py',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-02-22T21:39:41.228+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:39:41.270+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.123 seconds
[2023-02-22T21:40:11.756+0000] {processor.py:153} INFO - Started process (PID=1885) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:40:11.761+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:40:11.762+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:40:11.762+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:40:11.814+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:40:11.809+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 54, in <module>
    bash_command = 'python3 aws_geos.py',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-02-22T21:40:11.815+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:40:11.847+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.098 seconds
[2023-02-22T21:40:42.539+0000] {processor.py:153} INFO - Started process (PID=1921) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:40:42.542+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:40:42.544+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:40:42.544+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:40:42.589+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:40:42.584+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 54, in <module>
    bash_command = 'python3 aws_geos.py',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-02-22T21:40:42.592+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:40:42.629+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.095 seconds
[2023-02-22T21:41:13.065+0000] {processor.py:153} INFO - Started process (PID=1947) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:41:13.070+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:41:13.072+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:41:13.072+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:41:13.115+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:41:13.109+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 54, in <module>
    bash_command = 'python3 aws_geos.py',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-02-22T21:41:13.116+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:41:13.157+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.100 seconds
[2023-02-22T21:41:18.223+0000] {processor.py:153} INFO - Started process (PID=1948) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:41:18.225+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:41:18.230+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:41:18.230+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:41:18.324+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:41:18.311+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 55, in <module>
    bash_command = 'python3 aws_geos.py',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-02-22T21:41:18.327+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:41:18.369+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.155 seconds
[2023-02-22T21:41:19.292+0000] {processor.py:153} INFO - Started process (PID=1961) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:41:19.295+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:41:19.300+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:41:19.299+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:41:19.354+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:41:19.349+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 55, in <module>
    bash_command = 'python3 aws_geos.py',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-02-22T21:41:19.356+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:41:19.412+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.129 seconds
[2023-02-22T21:41:49.894+0000] {processor.py:153} INFO - Started process (PID=1985) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:41:49.896+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:41:49.897+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:41:49.897+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:41:49.951+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:41:49.945+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 55, in <module>
    bash_command = 'python3 aws_geos.py',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-02-22T21:41:49.953+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:41:49.992+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.103 seconds
[2023-02-22T21:42:20.486+0000] {processor.py:153} INFO - Started process (PID=2021) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:42:20.489+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:42:20.493+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:42:20.492+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:42:20.543+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:42:20.536+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 55, in <module>
    bash_command = 'python3 aws_geos.py',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-02-22T21:42:20.550+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:42:20.611+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.133 seconds
[2023-02-22T21:42:50.864+0000] {processor.py:153} INFO - Started process (PID=2047) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:42:50.871+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:42:50.872+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:42:50.872+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:42:50.915+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:42:50.908+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 55, in <module>
    bash_command = 'python3 aws_geos.py',
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 147, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 874, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 981, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1039, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2328, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-02-22T21:42:50.918+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:42:50.944+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.093 seconds
[2023-02-22T21:42:59.166+0000] {processor.py:153} INFO - Started process (PID=2059) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:42:59.168+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:42:59.169+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:42:59.169+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:42:59.183+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:42:59.181+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 93
    (t1,t2) >> (t3,t4) >> t5
                           ^
IndentationError: unindent does not match any outer indentation level
[2023-02-22T21:42:59.184+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:42:59.215+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.056 seconds
[2023-02-22T21:43:29.607+0000] {processor.py:153} INFO - Started process (PID=2084) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:43:29.610+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:43:29.613+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:43:29.611+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:43:29.627+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:43:29.626+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 93
    (t1,t2) >> (t3,t4) >> t5
                           ^
IndentationError: unindent does not match any outer indentation level
[2023-02-22T21:43:29.629+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:43:29.661+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.060 seconds
[2023-02-22T21:44:00.434+0000] {processor.py:153} INFO - Started process (PID=2122) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:44:00.442+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:44:00.449+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:44:00.449+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:44:00.483+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:44:00.477+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 93
    (t1,t2) >> (t3,t4) >> t5
                           ^
IndentationError: unindent does not match any outer indentation level
[2023-02-22T21:44:00.486+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:44:00.600+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.215 seconds
[2023-02-22T21:44:31.298+0000] {processor.py:153} INFO - Started process (PID=2146) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:44:31.301+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:44:31.302+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:44:31.302+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:44:31.316+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:44:31.314+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 93
    (t1,t2) >> (t3,t4) >> t5
                           ^
IndentationError: unindent does not match any outer indentation level
[2023-02-22T21:44:31.318+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:44:31.341+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.048 seconds
[2023-02-22T21:45:01.752+0000] {processor.py:153} INFO - Started process (PID=2172) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:45:01.755+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:45:01.757+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:45:01.756+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:45:01.767+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:45:01.765+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 93
    (t1,t2) >> (t3,t4) >> t5
                           ^
IndentationError: unindent does not match any outer indentation level
[2023-02-22T21:45:01.768+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:45:01.792+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.047 seconds
[2023-02-22T21:45:11.934+0000] {processor.py:153} INFO - Started process (PID=2186) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:45:11.938+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:45:11.945+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:45:11.945+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:45:11.958+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:45:11.956+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 94
    (t1,t2) >> (t3,t4) >> t5
                           ^
IndentationError: unindent does not match any outer indentation level
[2023-02-22T21:45:11.960+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:45:11.988+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.061 seconds
[2023-02-22T21:45:42.503+0000] {processor.py:153} INFO - Started process (PID=2222) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:45:42.512+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:45:42.514+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:45:42.514+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:45:42.526+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:45:42.525+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 94
    (t1,t2) >> (t3,t4) >> t5
                           ^
IndentationError: unindent does not match any outer indentation level
[2023-02-22T21:45:42.528+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:45:42.556+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.063 seconds
[2023-02-22T21:45:47.628+0000] {processor.py:153} INFO - Started process (PID=2223) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:45:47.630+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:45:47.632+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:45:47.632+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:45:47.700+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:45:47.697+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    (t1,t2) >> (t3,t4) >> t5
TypeError: unsupported operand type(s) for >>: 'tuple' and 'tuple'
[2023-02-22T21:45:47.702+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:45:47.740+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.119 seconds
[2023-02-22T21:46:18.305+0000] {processor.py:153} INFO - Started process (PID=2260) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:46:18.308+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:46:18.310+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:46:18.310+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:46:18.370+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:46:18.365+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    (t1,t2) >> (t3,t4) >> t5
TypeError: unsupported operand type(s) for >>: 'tuple' and 'tuple'
[2023-02-22T21:46:18.373+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:46:18.420+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.124 seconds
[2023-02-22T21:46:30.495+0000] {processor.py:153} INFO - Started process (PID=2273) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:46:30.498+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:46:30.504+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:46:30.504+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:46:30.569+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:46:30.566+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:46:30.574+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:46:30.600+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.112 seconds
[2023-02-22T21:47:00.916+0000] {processor.py:153} INFO - Started process (PID=2298) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:47:00.919+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:47:00.921+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:47:00.921+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:47:00.977+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:47:00.973+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:47:00.983+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:47:01.044+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.139 seconds
[2023-02-22T21:47:31.258+0000] {processor.py:153} INFO - Started process (PID=2335) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:47:31.261+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:47:31.263+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:47:31.263+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:47:31.295+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:47:31.293+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:47:31.296+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:47:31.319+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.069 seconds
[2023-02-22T21:48:01.778+0000] {processor.py:153} INFO - Started process (PID=2361) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:48:01.781+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:48:01.787+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:48:01.787+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:48:01.825+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:48:01.823+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:48:01.828+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:48:01.866+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.095 seconds
[2023-02-22T21:48:32.240+0000] {processor.py:153} INFO - Started process (PID=2398) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:48:32.243+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:48:32.245+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:48:32.244+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:48:32.288+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:48:32.285+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:48:32.291+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:48:32.317+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.083 seconds
[2023-02-22T21:49:02.672+0000] {processor.py:153} INFO - Started process (PID=2423) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:49:02.675+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:49:02.677+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:49:02.676+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:49:02.712+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:49:02.707+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:49:02.713+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:49:02.737+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.072 seconds
[2023-02-22T21:49:33.055+0000] {processor.py:153} INFO - Started process (PID=2461) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:49:33.057+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:49:33.059+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:49:33.059+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:49:33.119+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:49:33.115+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:49:33.120+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:49:33.151+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.101 seconds
[2023-02-22T21:50:03.555+0000] {processor.py:153} INFO - Started process (PID=2486) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:50:03.559+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:50:03.561+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:50:03.561+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:50:03.609+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:50:03.606+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:50:03.610+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:50:03.645+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.099 seconds
[2023-02-22T21:50:33.997+0000] {processor.py:153} INFO - Started process (PID=2524) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:50:34.000+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:50:34.001+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:50:34.001+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:50:34.039+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:50:34.037+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:50:34.042+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:50:34.068+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.076 seconds
[2023-02-22T21:51:04.462+0000] {processor.py:153} INFO - Started process (PID=2549) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:51:04.471+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:51:04.473+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:51:04.473+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:51:04.517+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:51:04.511+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:51:04.519+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:51:04.563+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.106 seconds
[2023-02-22T21:51:34.983+0000] {processor.py:153} INFO - Started process (PID=2586) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:51:34.986+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:51:34.988+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:51:34.988+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:51:35.024+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:51:35.022+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:51:35.026+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:51:35.054+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.076 seconds
[2023-02-22T21:52:05.500+0000] {processor.py:153} INFO - Started process (PID=2610) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:52:05.504+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:52:05.506+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:52:05.506+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:52:05.545+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:52:05.541+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:52:05.550+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:52:05.587+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.099 seconds
[2023-02-22T21:52:36.001+0000] {processor.py:153} INFO - Started process (PID=2648) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:52:36.003+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:52:36.005+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:52:36.005+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:52:36.049+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:52:36.043+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:52:36.051+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:52:36.084+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.087 seconds
[2023-02-22T21:53:06.496+0000] {processor.py:153} INFO - Started process (PID=2674) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:53:06.499+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:53:06.503+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:53:06.503+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:53:06.551+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:53:06.547+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:53:06.555+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:53:06.588+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.096 seconds
[2023-02-22T21:53:36.964+0000] {processor.py:153} INFO - Started process (PID=2712) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:53:36.971+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:53:36.972+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:53:36.972+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:53:37.017+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:53:37.013+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:53:37.019+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:53:37.048+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.089 seconds
[2023-02-22T21:54:07.399+0000] {processor.py:153} INFO - Started process (PID=2746) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:54:07.403+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:54:07.404+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:54:07.404+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:54:07.445+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:54:07.436+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:54:07.448+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:54:07.475+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.080 seconds
[2023-02-22T21:54:37.836+0000] {processor.py:153} INFO - Started process (PID=2772) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:54:37.840+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:54:37.842+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:54:37.841+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:54:37.893+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:54:37.887+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:54:37.895+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:54:37.931+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.101 seconds
[2023-02-22T21:55:08.351+0000] {processor.py:153} INFO - Started process (PID=2810) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:55:08.354+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:55:08.355+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:55:08.355+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:55:08.384+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:55:08.381+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:55:08.385+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:55:08.403+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.056 seconds
[2023-02-22T21:55:38.755+0000] {processor.py:153} INFO - Started process (PID=2835) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:55:38.757+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:55:38.758+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:55:38.758+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:55:38.793+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:55:38.790+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:55:38.795+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:55:38.822+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.071 seconds
[2023-02-22T21:56:09.221+0000] {processor.py:153} INFO - Started process (PID=2871) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:56:09.225+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:56:09.227+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:56:09.227+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:56:09.261+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:56:09.259+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:56:09.264+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:56:09.289+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.077 seconds
[2023-02-22T21:56:39.611+0000] {processor.py:153} INFO - Started process (PID=2896) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:56:39.613+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:56:39.617+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:56:39.617+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:56:39.661+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:56:39.659+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:56:39.662+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:56:39.693+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.087 seconds
[2023-02-22T21:57:10.486+0000] {processor.py:153} INFO - Started process (PID=2933) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:57:10.499+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:57:10.504+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:57:10.503+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:57:10.614+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:57:10.609+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:57:10.616+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:57:10.647+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.178 seconds
[2023-02-22T21:57:41.174+0000] {processor.py:153} INFO - Started process (PID=2958) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:57:41.189+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:57:41.200+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:57:41.197+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:57:41.430+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:57:41.421+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:57:41.450+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:57:41.512+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.378 seconds
[2023-02-22T21:58:12.780+0000] {processor.py:153} INFO - Started process (PID=2984) to work on /opt/airflow/dags/schedule.py
[2023-02-22T21:58:12.787+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T21:58:12.791+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:58:12.791+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T21:58:12.917+0000] {logging_mixin.py:137} INFO - [2023-02-22T21:58:12.911+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T21:58:12.923+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T21:58:12.990+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.236 seconds
[2023-02-22T22:04:07.035+0000] {processor.py:153} INFO - Started process (PID=2985) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:04:07.039+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:04:07.042+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:04:07.042+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:04:07.074+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:04:07.070+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T22:04:07.075+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:04:07.128+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.099 seconds
[2023-02-22T22:04:50.340+0000] {processor.py:153} INFO - Started process (PID=3010) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:04:50.368+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:04:50.379+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:04:50.377+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:04:52.928+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:04:52.881+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T22:04:52.949+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:04:54.553+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 4.273 seconds
[2023-02-22T22:08:10.589+0000] {processor.py:153} INFO - Started process (PID=3022) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:08:10.597+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:08:10.605+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:08:10.604+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:08:10.724+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:08:10.712+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    [t1,t2] >> [t3,t4] >> t5
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2023-02-22T22:08:10.730+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:08:10.807+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.252 seconds
[2023-02-22T22:08:16.744+0000] {processor.py:153} INFO - Started process (PID=3023) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:08:16.755+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:08:16.761+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:08:16.760+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:08:16.891+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:08:16.887+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >>t2 >> [t3,t4] >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: scrap_metadata>, <DAG: populate_db>}
[2023-02-22T22:08:16.899+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:08:16.938+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.213 seconds
[2023-02-22T22:08:47.004+0000] {processor.py:153} INFO - Started process (PID=3059) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:08:47.010+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:08:47.011+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:08:47.011+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:08:47.053+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:08:47.047+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >>t2 >> [t3,t4] >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: scrap_metadata>, <DAG: populate_db>}
[2023-02-22T22:08:47.055+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:08:47.096+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.099 seconds
[2023-02-22T22:09:14.654+0000] {processor.py:153} INFO - Started process (PID=3083) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:09:14.659+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:09:14.661+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:09:14.661+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:09:14.733+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:09:14.729+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: scrap_metadata>, <DAG: populate_db>}
[2023-02-22T22:09:14.738+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:09:14.795+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.157 seconds
[2023-02-22T22:09:45.160+0000] {processor.py:153} INFO - Started process (PID=3108) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:09:45.165+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:09:45.174+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:09:45.173+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:09:45.235+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:09:45.231+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: scrap_metadata>}
[2023-02-22T22:09:45.237+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:09:45.276+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.127 seconds
[2023-02-22T22:10:15.856+0000] {processor.py:153} INFO - Started process (PID=3145) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:10:15.859+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:10:15.866+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:10:15.866+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:10:15.902+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:10:15.900+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: scrap_metadata>, <DAG: populate_db>}
[2023-02-22T22:10:15.904+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:10:15.925+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.077 seconds
[2023-02-22T22:10:46.234+0000] {processor.py:153} INFO - Started process (PID=3170) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:10:46.236+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:10:46.239+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:10:46.238+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:10:46.267+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:10:46.265+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: scrap_metadata>, <DAG: populate_db>}
[2023-02-22T22:10:46.269+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:10:46.297+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.071 seconds
[2023-02-22T22:11:17.105+0000] {processor.py:153} INFO - Started process (PID=3206) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:11:17.108+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:11:17.110+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:11:17.110+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:11:17.160+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:11:17.155+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: scrap_metadata>, <DAG: populate_db>}
[2023-02-22T22:11:17.162+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:11:17.190+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.096 seconds
[2023-02-22T22:11:47.684+0000] {processor.py:153} INFO - Started process (PID=3231) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:11:47.687+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:11:47.689+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:11:47.689+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:11:47.730+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:11:47.727+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: scrap_metadata>, <DAG: populate_db>}
[2023-02-22T22:11:47.733+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:11:47.768+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.094 seconds
[2023-02-22T22:12:18.370+0000] {processor.py:153} INFO - Started process (PID=3268) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:12:18.373+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:12:18.375+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:12:18.374+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:12:18.412+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:12:18.410+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: scrap_metadata>}
[2023-02-22T22:12:18.414+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:12:18.445+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.082 seconds
[2023-02-22T22:12:49.012+0000] {processor.py:153} INFO - Started process (PID=3293) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:12:49.015+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:12:49.017+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:12:49.017+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:12:49.060+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:12:49.057+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: scrap_metadata>, <DAG: populate_db>}
[2023-02-22T22:12:49.062+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:12:49.092+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.095 seconds
[2023-02-22T22:13:19.507+0000] {processor.py:153} INFO - Started process (PID=3329) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:13:19.513+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:13:19.515+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:13:19.515+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:13:19.565+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:13:19.562+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: scrap_metadata>, <DAG: populate_db>}
[2023-02-22T22:13:19.571+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:13:19.613+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.114 seconds
[2023-02-22T22:13:50.097+0000] {processor.py:153} INFO - Started process (PID=3354) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:13:50.099+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:13:50.100+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:13:50.100+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:13:50.151+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:13:50.148+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: scrap_metadata>}
[2023-02-22T22:13:50.154+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:13:50.178+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.087 seconds
[2023-02-22T22:14:20.811+0000] {processor.py:153} INFO - Started process (PID=3390) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:14:20.820+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:14:20.827+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:14:20.827+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:14:20.912+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:14:20.903+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: scrap_metadata>}
[2023-02-22T22:14:20.916+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:14:20.973+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.180 seconds
[2023-02-22T22:14:51.244+0000] {processor.py:153} INFO - Started process (PID=3415) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:14:51.249+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:14:51.253+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:14:51.252+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:14:51.304+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:14:51.300+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: scrap_metadata>, <DAG: populate_db>}
[2023-02-22T22:14:51.305+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:14:51.349+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.122 seconds
[2023-02-22T22:15:21.912+0000] {processor.py:153} INFO - Started process (PID=3440) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:15:21.916+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:15:21.917+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:15:21.917+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:15:21.970+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:15:21.965+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: scrap_metadata>}
[2023-02-22T22:15:21.972+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:15:22.017+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.109 seconds
[2023-02-22T22:15:52.316+0000] {processor.py:153} INFO - Started process (PID=3477) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:15:52.318+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:15:52.320+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:15:52.320+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:15:52.368+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:15:52.365+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: scrap_metadata>, <DAG: populate_db>}
[2023-02-22T22:15:52.371+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:15:52.401+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.093 seconds
[2023-02-22T22:16:22.746+0000] {processor.py:153} INFO - Started process (PID=3502) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:16:22.750+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:16:22.752+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:16:22.752+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:16:22.793+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:16:22.789+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: scrap_metadata>, <DAG: populate_db>}
[2023-02-22T22:16:22.798+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:16:22.828+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.088 seconds
[2023-02-22T22:16:53.256+0000] {processor.py:153} INFO - Started process (PID=3539) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:16:53.261+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:16:53.264+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:16:53.263+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:16:53.305+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:16:53.302+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: scrap_metadata>}
[2023-02-22T22:16:53.306+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:16:53.338+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.092 seconds
[2023-02-22T22:17:23.737+0000] {processor.py:153} INFO - Started process (PID=3572) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:17:23.740+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:17:23.745+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:17:23.745+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:17:23.796+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:17:23.793+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: scrap_metadata>, <DAG: populate_db>}
[2023-02-22T22:17:23.798+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:17:23.839+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.108 seconds
[2023-02-22T22:17:54.245+0000] {processor.py:153} INFO - Started process (PID=3600) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:17:54.248+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:17:54.250+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:17:54.250+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:17:54.292+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:17:54.287+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: scrap_metadata>}
[2023-02-22T22:17:54.293+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:17:54.329+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.090 seconds
[2023-02-22T22:18:24.665+0000] {processor.py:153} INFO - Started process (PID=3630) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:18:24.671+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:18:24.673+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:18:24.673+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:18:24.727+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:18:24.723+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: scrap_metadata>, <DAG: populate_db>}
[2023-02-22T22:18:24.730+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:18:24.770+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.114 seconds
[2023-02-22T22:18:55.030+0000] {processor.py:153} INFO - Started process (PID=3660) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:18:55.033+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:18:55.034+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:18:55.034+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:18:55.077+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:18:55.074+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: scrap_metadata>}
[2023-02-22T22:18:55.079+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:18:55.110+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.094 seconds
[2023-02-22T22:19:25.483+0000] {processor.py:153} INFO - Started process (PID=3697) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:19:25.486+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:19:25.488+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:19:25.487+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:19:25.541+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:19:25.533+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t1 >> t2 >> t3 >> t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: scrap_metadata>}
[2023-02-22T22:19:25.543+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:19:25.589+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.112 seconds
[2023-02-22T22:19:44.769+0000] {processor.py:153} INFO - Started process (PID=3710) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:19:44.773+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:19:44.775+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:19:44.774+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:19:44.861+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:19:45.061+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:19:45.061+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:19:45.116+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:19:45.116+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:19:45.122+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:19:45.122+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:19:45.130+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:19:45.129+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:19:45.171+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.408 seconds
[2023-02-22T22:20:15.654+0000] {processor.py:153} INFO - Started process (PID=3744) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:20:15.657+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:20:15.659+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:20:15.659+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:20:15.733+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:20:15.792+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:20:15.791+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:20:15.823+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:20:15.823+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:20:15.829+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:20:15.829+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:20:15.834+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:20:15.834+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:20:15.854+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.212 seconds
[2023-02-22T22:20:46.059+0000] {processor.py:153} INFO - Started process (PID=3772) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:20:46.063+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:20:46.065+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:20:46.065+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:20:46.109+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:20:46.148+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:20:46.147+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:20:46.172+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:20:46.172+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:20:46.176+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:20:46.175+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:20:46.178+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:20:46.178+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:20:46.191+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.139 seconds
[2023-02-22T22:21:16.635+0000] {processor.py:153} INFO - Started process (PID=3805) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:21:16.638+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:21:16.640+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:21:16.640+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:21:16.690+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:21:16.746+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:21:16.746+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:21:16.799+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:21:16.799+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:21:16.803+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:21:16.803+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:21:16.807+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:21:16.807+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:21:16.828+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.204 seconds
[2023-02-22T22:21:47.010+0000] {processor.py:153} INFO - Started process (PID=3833) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:21:47.014+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:21:47.017+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:21:47.017+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:21:47.069+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:21:47.107+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:21:47.107+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:21:47.139+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:21:47.139+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:21:47.143+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:21:47.143+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:21:47.146+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:21:47.146+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:21:47.158+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.158 seconds
[2023-02-22T22:22:17.404+0000] {processor.py:153} INFO - Started process (PID=3870) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:22:17.407+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:22:17.410+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:22:17.410+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:22:17.456+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:22:17.507+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:22:17.506+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:22:17.538+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:22:17.538+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:22:17.543+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:22:17.543+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:22:17.547+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:22:17.547+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:22:17.569+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.170 seconds
[2023-02-22T22:22:47.793+0000] {processor.py:153} INFO - Started process (PID=3896) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:22:47.797+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:22:47.799+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:22:47.799+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:22:47.848+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:22:47.889+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:22:47.889+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:22:47.917+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:22:47.917+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:22:47.920+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:22:47.920+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:22:47.923+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:22:47.923+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:22:47.940+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.151 seconds
[2023-02-22T22:23:18.137+0000] {processor.py:153} INFO - Started process (PID=3932) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:23:18.141+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:23:18.142+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:23:18.142+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:23:18.174+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:23:18.210+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:23:18.210+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:23:18.231+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:23:18.231+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:23:18.235+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:23:18.235+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:23:18.238+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:23:18.237+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:23:18.252+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.120 seconds
[2023-02-22T22:23:48.516+0000] {processor.py:153} INFO - Started process (PID=3955) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:23:48.519+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:23:48.520+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:23:48.520+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:23:48.566+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:23:48.611+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:23:48.610+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:23:48.649+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:23:48.649+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:23:48.652+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:23:48.652+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:23:48.655+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:23:48.655+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:23:48.668+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.158 seconds
[2023-02-22T22:24:19.129+0000] {processor.py:153} INFO - Started process (PID=3992) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:24:19.133+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:24:19.134+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:24:19.134+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:24:19.190+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:24:19.240+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:24:19.240+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:24:19.277+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:24:19.277+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:24:19.282+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:24:19.281+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:24:19.286+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:24:19.285+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:24:19.300+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.178 seconds
[2023-02-22T22:24:49.586+0000] {processor.py:153} INFO - Started process (PID=4017) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:24:49.590+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:24:49.592+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:24:49.592+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:24:49.652+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:24:49.693+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:24:49.693+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:24:49.720+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:24:49.720+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:24:49.724+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:24:49.724+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:24:49.726+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:24:49.726+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:24:49.742+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.166 seconds
[2023-02-22T22:25:20.102+0000] {processor.py:153} INFO - Started process (PID=4054) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:25:20.105+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:25:20.106+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:25:20.106+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:25:20.156+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:25:20.202+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:25:20.201+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:25:20.231+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:25:20.231+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:25:20.236+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:25:20.236+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:25:20.239+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:25:20.239+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:25:20.260+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.164 seconds
[2023-02-22T22:25:50.576+0000] {processor.py:153} INFO - Started process (PID=4079) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:25:50.588+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:25:50.589+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:25:50.589+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:25:50.635+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:25:50.709+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:25:50.709+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:25:50.748+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:25:50.748+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:25:50.752+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:25:50.752+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:25:50.755+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:25:50.755+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:25:50.778+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.210 seconds
[2023-02-22T22:25:51.622+0000] {processor.py:153} INFO - Started process (PID=4080) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:25:51.624+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:25:51.626+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:25:51.626+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:25:51.671+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:25:51.668+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:25:51.672+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:25:51.695+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.078 seconds
[2023-02-22T22:26:22.457+0000] {processor.py:153} INFO - Started process (PID=4118) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:26:22.461+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:26:22.463+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:26:22.462+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:26:22.508+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:26:22.505+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:26:22.509+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:26:22.539+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.095 seconds
[2023-02-22T22:26:52.860+0000] {processor.py:153} INFO - Started process (PID=4143) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:26:52.868+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:26:52.870+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:26:52.869+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:26:52.920+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:26:52.916+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:26:52.922+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:26:52.959+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.103 seconds
[2023-02-22T22:27:23.283+0000] {processor.py:153} INFO - Started process (PID=4181) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:27:23.286+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:27:23.288+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:27:23.288+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:27:23.330+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:27:23.327+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:27:23.332+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:27:23.355+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.080 seconds
[2023-02-22T22:27:53.840+0000] {processor.py:153} INFO - Started process (PID=4205) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:27:53.845+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:27:53.847+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:27:53.847+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:27:53.905+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:27:53.903+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:27:53.908+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:27:53.940+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.107 seconds
[2023-02-22T22:28:24.305+0000] {processor.py:153} INFO - Started process (PID=4242) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:28:24.309+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:28:24.310+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:28:24.310+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:28:24.354+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:28:24.350+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:28:24.356+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:28:24.387+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.089 seconds
[2023-02-22T22:28:54.858+0000] {processor.py:153} INFO - Started process (PID=4267) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:28:54.862+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:28:54.863+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:28:54.863+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:28:54.904+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:28:54.902+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:28:54.910+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:28:54.940+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.093 seconds
[2023-02-22T22:29:25.299+0000] {processor.py:153} INFO - Started process (PID=4304) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:29:25.302+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:29:25.304+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:29:25.304+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:29:25.346+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:29:25.343+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:29:25.349+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:29:25.384+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.094 seconds
[2023-02-22T22:29:55.805+0000] {processor.py:153} INFO - Started process (PID=4330) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:29:55.809+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:29:55.810+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:29:55.810+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:29:55.842+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:29:55.840+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:29:55.844+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:29:55.876+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.077 seconds
[2023-02-22T22:30:26.170+0000] {processor.py:153} INFO - Started process (PID=4367) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:30:26.173+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:30:26.174+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:30:26.174+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:30:26.206+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:30:26.203+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:30:26.211+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:30:26.232+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.067 seconds
[2023-02-22T22:30:56.639+0000] {processor.py:153} INFO - Started process (PID=4392) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:30:56.643+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:30:56.644+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:30:56.644+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:30:56.689+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:30:56.685+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:30:56.690+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:30:56.722+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.091 seconds
[2023-02-22T22:31:27.088+0000] {processor.py:153} INFO - Started process (PID=4429) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:31:27.091+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:31:27.093+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:31:27.093+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:31:27.130+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:31:27.127+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:31:27.135+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:31:27.162+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.079 seconds
[2023-02-22T22:31:57.582+0000] {processor.py:153} INFO - Started process (PID=4454) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:31:57.586+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:31:57.588+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:31:57.588+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:31:57.642+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:31:57.637+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:31:57.646+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:31:57.681+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.108 seconds
[2023-02-22T22:32:28.033+0000] {processor.py:153} INFO - Started process (PID=4491) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:32:28.036+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:32:28.037+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:32:28.037+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:32:28.081+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:32:28.075+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:32:28.083+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:32:28.117+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.090 seconds
[2023-02-22T22:32:58.493+0000] {processor.py:153} INFO - Started process (PID=4516) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:32:58.499+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:32:58.501+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:32:58.501+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:32:58.544+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:32:58.538+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:32:58.545+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:32:58.581+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.096 seconds
[2023-02-22T22:33:28.961+0000] {processor.py:153} INFO - Started process (PID=4554) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:33:28.964+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:33:28.966+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:33:28.966+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:33:29.006+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:33:29.003+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:33:29.010+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:33:29.031+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.080 seconds
[2023-02-22T22:33:59.301+0000] {processor.py:153} INFO - Started process (PID=4579) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:33:59.306+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:33:59.308+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:33:59.307+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:33:59.358+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:33:59.355+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:33:59.361+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:33:59.393+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.097 seconds
[2023-02-22T22:34:29.848+0000] {processor.py:153} INFO - Started process (PID=4616) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:34:29.852+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:34:29.853+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:34:29.853+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:34:29.903+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:34:29.899+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:34:29.905+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:34:29.928+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.085 seconds
[2023-02-22T22:35:00.248+0000] {processor.py:153} INFO - Started process (PID=4641) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:35:00.251+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:35:00.253+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:35:00.253+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:35:00.288+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:35:00.285+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:35:00.289+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:35:00.321+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.079 seconds
[2023-02-22T22:35:30.754+0000] {processor.py:153} INFO - Started process (PID=4679) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:35:30.761+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:35:30.763+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:35:30.763+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:35:30.806+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:35:30.803+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:35:30.808+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:35:30.839+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.091 seconds
[2023-02-22T22:36:01.219+0000] {processor.py:153} INFO - Started process (PID=4704) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:36:01.225+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:36:01.227+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:36:01.227+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:36:01.312+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:36:01.306+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:36:01.314+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:36:01.353+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.145 seconds
[2023-02-22T22:36:31.670+0000] {processor.py:153} INFO - Started process (PID=4742) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:36:31.673+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:36:31.675+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:36:31.674+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:36:31.726+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:36:31.723+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:36:31.727+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:36:31.755+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.091 seconds
[2023-02-22T22:37:02.094+0000] {processor.py:153} INFO - Started process (PID=4774) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:37:02.097+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:37:02.099+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:37:02.099+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:37:02.159+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:37:02.155+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:37:02.166+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:37:02.206+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.116 seconds
[2023-02-22T22:37:32.584+0000] {processor.py:153} INFO - Started process (PID=4803) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:37:32.587+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:37:32.589+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:37:32.589+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:37:32.620+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:37:32.617+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:37:32.625+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:37:32.652+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.073 seconds
[2023-02-22T22:38:03.032+0000] {processor.py:153} INFO - Started process (PID=4836) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:38:03.036+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:38:03.039+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:38:03.039+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:38:03.106+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:38:03.099+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:38:03.122+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:38:03.194+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.169 seconds
[2023-02-22T22:38:33.465+0000] {processor.py:153} INFO - Started process (PID=4866) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:38:33.469+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:38:33.471+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:38:33.471+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:38:33.522+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:38:33.519+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:38:33.523+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:38:33.562+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.108 seconds
[2023-02-22T22:39:03.964+0000] {processor.py:153} INFO - Started process (PID=4891) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:39:03.968+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:39:03.970+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:39:03.970+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:39:04.012+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:39:04.009+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:39:04.013+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:39:04.039+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.082 seconds
[2023-02-22T22:39:34.615+0000] {processor.py:153} INFO - Started process (PID=4926) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:39:34.620+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:39:34.621+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:39:34.621+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:39:34.661+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:39:34.658+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 95, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:39:34.662+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:39:34.697+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.092 seconds
[2023-02-22T22:39:51.914+0000] {processor.py:153} INFO - Started process (PID=4939) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:39:51.918+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:39:51.919+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:39:51.919+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:39:51.989+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:39:51.985+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 101, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:39:52.000+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:39:52.058+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.150 seconds
[2023-02-22T22:40:22.535+0000] {processor.py:153} INFO - Started process (PID=4977) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:40:22.538+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:40:22.541+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:40:22.540+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:40:22.593+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:40:22.590+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 101, in <module>
    t4 >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 81, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 230, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:40:22.599+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:40:22.638+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.110 seconds
[2023-02-22T22:40:24.621+0000] {processor.py:153} INFO - Started process (PID=4978) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:40:24.624+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:40:24.625+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:40:24.625+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:40:24.672+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:40:24.668+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 101, in <module>
    [t3,t4] >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 86, in __rrshift__
    self.__lshift__(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 76, in __lshift__
    self.set_upstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 238, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:40:24.674+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:40:24.697+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.082 seconds
[2023-02-22T22:40:55.119+0000] {processor.py:153} INFO - Started process (PID=5004) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:40:55.121+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:40:55.123+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:40:55.122+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:40:55.172+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:40:55.168+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 101, in <module>
    [t3,t4] >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 86, in __rrshift__
    self.__lshift__(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 76, in __lshift__
    self.set_upstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 238, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:40:55.175+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:40:55.211+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.101 seconds
[2023-02-22T22:41:25.575+0000] {processor.py:153} INFO - Started process (PID=5040) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:41:25.578+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:41:25.579+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:41:25.579+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:41:25.621+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:41:25.618+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 101, in <module>
    [t3,t4] >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 86, in __rrshift__
    self.__lshift__(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 76, in __lshift__
    self.set_upstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 238, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: populate_db>, <DAG: db_to_csv>}
[2023-02-22T22:41:25.624+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:41:25.649+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.081 seconds
[2023-02-22T22:41:56.070+0000] {processor.py:153} INFO - Started process (PID=5076) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:41:56.073+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:41:56.076+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:41:56.076+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:41:56.118+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:41:56.115+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/schedule.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/schedule.py", line 101, in <module>
    [t3,t4] >> t5
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 86, in __rrshift__
    self.__lshift__(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 76, in __lshift__
    self.set_upstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 238, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 189, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: db_to_csv>, <DAG: populate_db>}
[2023-02-22T22:41:56.120+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:41:56.160+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.098 seconds
[2023-02-22T22:42:22.454+0000] {processor.py:153} INFO - Started process (PID=5101) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:42:22.461+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:42:22.463+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:42:22.463+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:42:22.567+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:42:22.657+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:42:22.656+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:42:22.679+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:42:22.679+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:42:22.687+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:42:22.687+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:42:22.691+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:42:22.691+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:42:22.718+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.275 seconds
[2023-02-22T22:42:52.982+0000] {processor.py:153} INFO - Started process (PID=5126) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:42:52.985+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:42:52.986+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:42:52.986+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:42:53.021+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:42:53.062+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:42:53.061+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:42:53.099+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:42:53.099+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:42:53.107+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:42:53.107+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:42:53.110+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:42:53.110+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:42:53.136+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.158 seconds
[2023-02-22T22:43:23.615+0000] {processor.py:153} INFO - Started process (PID=5163) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:43:23.624+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:43:23.629+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:43:23.629+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:43:23.665+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:43:23.701+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:43:23.701+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:43:23.721+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:43:23.720+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:43:23.724+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:43:23.723+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:43:23.726+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:43:23.726+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:43:23.742+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.134 seconds
[2023-02-22T22:43:54.028+0000] {processor.py:153} INFO - Started process (PID=5186) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:43:54.032+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:43:54.034+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:43:54.034+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:43:54.083+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:43:54.125+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:43:54.124+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:43:54.147+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:43:54.147+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:43:54.152+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:43:54.152+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:43:54.155+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:43:54.155+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:43:54.170+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.148 seconds
[2023-02-22T22:44:24.484+0000] {processor.py:153} INFO - Started process (PID=5223) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:44:24.489+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:44:24.491+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:44:24.491+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:44:24.536+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:44:24.577+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:44:24.577+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:44:24.602+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:44:24.601+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:44:24.606+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:44:24.606+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:44:24.609+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:44:24.609+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:44:24.629+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.150 seconds
[2023-02-22T22:44:54.919+0000] {processor.py:153} INFO - Started process (PID=5247) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:44:54.926+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:44:54.928+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:44:54.928+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:44:54.976+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:44:55.024+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:44:55.024+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:44:55.057+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:44:55.057+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:44:55.062+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:44:55.062+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:44:55.065+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:44:55.065+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:44:55.079+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.166 seconds
[2023-02-22T22:44:55.925+0000] {processor.py:153} INFO - Started process (PID=5248) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:44:55.927+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:44:55.933+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:44:55.933+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:44:55.965+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:44:56.019+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:44:56.018+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:44:56.040+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:44:56.040+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:44:56.044+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:44:56.044+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:44:56.046+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:44:56.046+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:44:56.062+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.140 seconds
[2023-02-22T22:45:26.547+0000] {processor.py:153} INFO - Started process (PID=5285) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:45:26.550+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:45:26.551+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:45:26.551+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:45:26.589+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:45:26.619+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:45:26.619+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:45:26.646+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:45:26.645+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:45:26.649+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:45:26.649+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:45:26.651+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:45:26.651+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:45:26.663+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.122 seconds
[2023-02-22T22:45:56.994+0000] {processor.py:153} INFO - Started process (PID=5310) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:45:56.997+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:45:57.003+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:45:57.003+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:45:57.054+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:45:57.095+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:45:57.095+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:45:57.125+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:45:57.125+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:45:57.129+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:45:57.129+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:45:57.132+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:45:57.132+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:45:57.145+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.159 seconds
[2023-02-22T22:46:27.364+0000] {processor.py:153} INFO - Started process (PID=5346) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:46:27.367+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:46:27.369+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:46:27.369+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:46:27.410+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:46:27.445+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:46:27.445+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:46:27.472+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:46:27.472+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:46:27.477+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:46:27.477+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:46:27.480+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:46:27.480+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:46:27.494+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.137 seconds
[2023-02-22T22:46:57.893+0000] {processor.py:153} INFO - Started process (PID=5372) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:46:57.902+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:46:57.907+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:46:57.907+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:46:57.969+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:46:58.020+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:46:58.020+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:46:58.051+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:46:58.051+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:46:58.055+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:46:58.055+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:46:58.059+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:46:58.059+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:46:58.075+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.189 seconds
[2023-02-22T22:47:28.297+0000] {processor.py:153} INFO - Started process (PID=5410) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:47:28.303+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:47:28.305+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:47:28.304+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:47:28.357+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:47:28.395+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:47:28.395+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:47:28.420+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:47:28.420+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:47:28.424+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:47:28.424+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:47:28.426+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:47:28.426+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:47:28.438+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.150 seconds
[2023-02-22T22:47:58.765+0000] {processor.py:153} INFO - Started process (PID=5436) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:47:58.768+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:47:58.770+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:47:58.770+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:47:58.808+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:47:58.843+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:47:58.843+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:47:58.862+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:47:58.862+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:47:58.866+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:47:58.866+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:47:58.869+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:47:58.869+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:47:58.883+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.131 seconds
[2023-02-22T22:48:29.359+0000] {processor.py:153} INFO - Started process (PID=5473) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:48:29.363+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:48:29.364+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:48:29.364+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:48:29.409+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:48:29.444+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:48:29.444+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:48:29.466+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:48:29.466+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:48:29.470+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:48:29.470+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:48:29.473+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:48:29.473+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:48:29.484+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.135 seconds
[2023-02-22T22:48:59.727+0000] {processor.py:153} INFO - Started process (PID=5499) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:48:59.730+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:48:59.731+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:48:59.731+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:48:59.790+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:48:59.841+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:48:59.841+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:48:59.887+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:48:59.887+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:48:59.898+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:48:59.898+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:48:59.901+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:48:59.901+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:48:59.915+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.193 seconds
[2023-02-22T22:49:30.088+0000] {processor.py:153} INFO - Started process (PID=5536) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:49:30.091+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:49:30.093+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:49:30.093+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:49:30.139+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:49:30.191+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:49:30.191+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:49:30.225+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:49:30.225+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:49:30.229+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:49:30.229+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:49:30.232+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:49:30.232+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:49:30.247+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.170 seconds
[2023-02-22T22:50:00.473+0000] {processor.py:153} INFO - Started process (PID=5569) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:50:00.480+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:50:00.483+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:50:00.483+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:50:00.537+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:50:00.592+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:50:00.592+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:50:00.624+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:50:00.624+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:50:00.628+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:50:00.628+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:50:00.632+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:50:00.632+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:50:00.654+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.203 seconds
[2023-02-22T22:50:30.848+0000] {processor.py:153} INFO - Started process (PID=5599) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:50:30.851+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:50:30.854+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:50:30.854+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:50:30.980+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:50:31.034+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:50:31.033+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:50:31.062+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:50:31.062+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:50:31.066+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:50:31.066+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:50:31.072+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:50:31.072+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:50:31.086+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.244 seconds
[2023-02-22T22:51:01.382+0000] {processor.py:153} INFO - Started process (PID=5634) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:51:01.389+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:51:01.391+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:51:01.391+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:51:01.451+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:51:01.506+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:51:01.506+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:51:01.545+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:51:01.545+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:51:01.551+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:51:01.551+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:51:01.555+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:51:01.555+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:51:01.579+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.204 seconds
[2023-02-22T22:51:31.967+0000] {processor.py:153} INFO - Started process (PID=5663) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:51:31.970+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:51:31.972+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:51:31.972+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:51:32.019+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:51:32.064+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:51:32.064+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:51:32.091+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:51:32.091+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:51:32.095+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:51:32.095+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:51:32.098+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:51:32.098+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:51:32.112+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.152 seconds
[2023-02-22T22:52:02.668+0000] {processor.py:153} INFO - Started process (PID=5688) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:52:02.671+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:52:02.673+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:52:02.673+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:52:02.716+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:52:02.761+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:52:02.761+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:52:02.795+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:52:02.795+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:52:02.800+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:52:02.800+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:52:02.803+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:52:02.803+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:52:02.821+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.158 seconds
[2023-02-22T22:52:33.159+0000] {processor.py:153} INFO - Started process (PID=5725) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:52:33.161+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:52:33.163+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:52:33.163+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:52:33.210+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:52:33.256+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:52:33.255+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:52:33.290+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:52:33.290+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:52:33.294+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:52:33.294+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:52:33.297+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:52:33.297+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:52:33.316+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.162 seconds
[2023-02-22T22:53:03.906+0000] {processor.py:153} INFO - Started process (PID=5751) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:53:03.911+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:53:03.912+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:53:03.912+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:53:03.975+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:53:04.035+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:53:04.034+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:53:04.089+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:53:04.089+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:53:04.094+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:53:04.094+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:53:04.098+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:53:04.097+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:53:04.117+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.217 seconds
[2023-02-22T22:53:34.363+0000] {processor.py:153} INFO - Started process (PID=5788) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:53:34.367+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:53:34.369+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:53:34.369+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:53:34.406+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:53:34.441+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:53:34.441+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:53:34.461+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:53:34.461+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:53:34.464+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:53:34.464+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:53:34.467+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:53:34.467+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:53:34.486+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.129 seconds
[2023-02-22T22:54:04.802+0000] {processor.py:153} INFO - Started process (PID=5813) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:54:04.808+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:54:04.810+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:54:04.810+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:54:04.868+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:54:04.935+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:54:04.934+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:54:04.978+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:54:04.978+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:54:04.984+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:54:04.984+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:54:04.988+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:54:04.988+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:54:05.008+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.212 seconds
[2023-02-22T22:54:35.349+0000] {processor.py:153} INFO - Started process (PID=5849) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:54:35.352+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:54:35.353+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:54:35.353+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:54:35.423+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:54:35.485+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:54:35.485+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:54:35.521+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:54:35.521+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:54:35.526+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:54:35.526+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:54:35.529+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:54:35.529+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:54:35.549+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.208 seconds
[2023-02-22T22:55:05.755+0000] {processor.py:153} INFO - Started process (PID=5874) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:55:05.758+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:55:05.760+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:55:05.760+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:55:05.805+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:55:05.846+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:55:05.846+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:55:05.870+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:55:05.870+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:55:05.874+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:55:05.874+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:55:05.876+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:55:05.876+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:55:05.895+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.146 seconds
[2023-02-22T22:55:36.194+0000] {processor.py:153} INFO - Started process (PID=5911) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:55:36.197+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:55:36.201+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:55:36.201+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:55:36.248+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:55:36.290+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:55:36.290+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:55:36.319+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:55:36.319+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:55:36.323+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:55:36.323+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:55:36.326+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:55:36.326+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:55:36.344+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.155 seconds
[2023-02-22T22:56:06.576+0000] {processor.py:153} INFO - Started process (PID=5936) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:56:06.581+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:56:06.582+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:56:06.582+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:56:06.651+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:56:06.733+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:56:06.733+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:56:06.784+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:56:06.783+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:56:06.791+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:56:06.790+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:56:06.797+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:56:06.797+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:56:06.815+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.249 seconds
[2023-02-22T22:56:37.062+0000] {processor.py:153} INFO - Started process (PID=5973) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:56:37.071+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:56:37.072+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:56:37.072+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:56:37.103+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:56:37.139+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:56:37.139+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:56:37.168+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:56:37.168+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:56:37.172+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:56:37.172+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:56:37.175+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:56:37.175+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:56:37.186+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.133 seconds
[2023-02-22T22:57:07.497+0000] {processor.py:153} INFO - Started process (PID=6007) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:57:07.500+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:57:07.504+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:57:07.503+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:57:07.561+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:57:07.612+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:57:07.612+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:57:07.644+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:57:07.644+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:57:07.650+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:57:07.650+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:57:07.656+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:57:07.656+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:57:07.682+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.193 seconds
[2023-02-22T22:57:37.921+0000] {processor.py:153} INFO - Started process (PID=6035) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:57:37.925+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:57:37.926+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:57:37.926+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:57:37.976+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:57:38.037+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:57:38.037+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:57:38.071+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:57:38.071+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:57:38.076+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:57:38.076+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:57:38.080+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:57:38.080+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:57:38.093+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.184 seconds
[2023-02-22T22:58:08.610+0000] {processor.py:153} INFO - Started process (PID=6060) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:58:08.613+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:58:08.615+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:58:08.614+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:58:08.677+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:58:08.726+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:58:08.726+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:58:08.760+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:58:08.760+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:58:08.764+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:58:08.764+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:58:08.769+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:58:08.769+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:58:08.792+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.193 seconds
[2023-02-22T22:58:39.196+0000] {processor.py:153} INFO - Started process (PID=6098) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:58:39.203+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:58:39.205+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:58:39.205+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:58:39.265+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:58:39.314+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:58:39.313+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:58:39.350+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:58:39.350+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:58:39.354+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:58:39.354+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:58:39.357+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:58:39.357+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:58:39.375+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.191 seconds
[2023-02-22T22:59:09.690+0000] {processor.py:153} INFO - Started process (PID=6122) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:59:09.694+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:59:09.696+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:59:09.696+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:59:09.745+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:59:09.785+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:59:09.785+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:59:09.825+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:59:09.825+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:59:09.830+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:59:09.829+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:59:09.832+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:59:09.832+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:59:09.851+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.168 seconds
[2023-02-22T22:59:40.341+0000] {processor.py:153} INFO - Started process (PID=6159) to work on /opt/airflow/dags/schedule.py
[2023-02-22T22:59:40.344+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T22:59:40.355+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:59:40.355+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T22:59:40.445+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T22:59:40.485+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:59:40.485+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T22:59:40.513+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:59:40.513+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T22:59:40.517+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:59:40.517+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T22:59:40.520+0000] {logging_mixin.py:137} INFO - [2023-02-22T22:59:40.520+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T22:59:40.534+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.200 seconds
[2023-02-22T23:00:10.747+0000] {processor.py:153} INFO - Started process (PID=6182) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:00:10.753+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:00:10.756+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:00:10.756+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:00:10.806+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:00:10.858+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:00:10.858+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:00:10.898+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:00:10.898+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:00:10.903+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:00:10.902+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:00:10.906+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:00:10.906+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:00:10.923+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.193 seconds
[2023-02-22T23:00:41.279+0000] {processor.py:153} INFO - Started process (PID=6218) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:00:41.282+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:00:41.283+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:00:41.283+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:00:41.318+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:00:41.355+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:00:41.355+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:00:41.378+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:00:41.378+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:00:41.383+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:00:41.383+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:00:41.385+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:00:41.385+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:00:41.397+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.132 seconds
[2023-02-22T23:01:11.623+0000] {processor.py:153} INFO - Started process (PID=6243) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:01:11.626+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:01:11.628+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:01:11.628+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:01:11.658+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:01:11.689+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:01:11.688+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:01:11.713+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:01:11.713+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:01:11.716+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:01:11.716+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:01:11.718+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:01:11.718+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:01:11.730+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.111 seconds
[2023-02-22T23:01:42.017+0000] {processor.py:153} INFO - Started process (PID=6281) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:01:42.020+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:01:42.025+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:01:42.024+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:01:42.069+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:01:42.103+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:01:42.102+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:01:42.129+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:01:42.129+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:01:42.133+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:01:42.133+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:01:42.135+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:01:42.135+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:01:42.147+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.137 seconds
[2023-02-22T23:02:12.449+0000] {processor.py:153} INFO - Started process (PID=6306) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:02:12.452+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:02:12.454+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:02:12.454+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:02:12.501+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:02:12.548+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:02:12.548+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:02:12.576+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:02:12.576+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:02:12.579+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:02:12.579+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:02:12.582+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:02:12.582+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:02:12.603+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.162 seconds
[2023-02-22T23:02:42.944+0000] {processor.py:153} INFO - Started process (PID=6343) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:02:42.947+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:02:42.948+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:02:42.948+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:02:42.998+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:02:43.047+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:02:43.047+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:02:43.077+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:02:43.077+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:02:43.097+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:02:43.097+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:02:43.113+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:02:43.113+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:02:43.169+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.231 seconds
[2023-02-22T23:03:13.336+0000] {processor.py:153} INFO - Started process (PID=6368) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:03:13.339+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:03:13.341+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:03:13.340+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:03:13.394+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:03:13.456+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:03:13.456+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:03:13.492+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:03:13.492+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:03:13.497+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:03:13.497+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:03:13.502+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:03:13.502+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:03:13.517+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.189 seconds
[2023-02-22T23:03:44.078+0000] {processor.py:153} INFO - Started process (PID=6405) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:03:44.086+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:03:44.087+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:03:44.087+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:03:44.129+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:03:44.165+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:03:44.165+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:03:44.188+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:03:44.188+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:03:44.193+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:03:44.193+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:03:44.201+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:03:44.200+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:03:44.215+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.146 seconds
[2023-02-22T23:04:14.563+0000] {processor.py:153} INFO - Started process (PID=6429) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:04:14.566+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:04:14.567+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:04:14.567+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:04:14.636+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:04:14.687+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:04:14.687+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:04:14.716+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:04:14.716+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:04:14.720+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:04:14.720+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:04:14.723+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:04:14.723+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:04:14.737+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.189 seconds
[2023-02-22T23:04:45.143+0000] {processor.py:153} INFO - Started process (PID=6467) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:04:45.145+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:04:45.147+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:04:45.147+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:04:45.188+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:04:45.239+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:04:45.239+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:04:45.279+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:04:45.279+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:04:45.284+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:04:45.283+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:04:45.287+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:04:45.287+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:04:45.307+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.173 seconds
[2023-02-22T23:05:15.509+0000] {processor.py:153} INFO - Started process (PID=6492) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:05:15.512+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:05:15.519+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:05:15.519+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:05:15.566+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:05:15.610+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:05:15.609+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:05:15.637+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:05:15.637+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:05:15.641+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:05:15.640+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:05:15.643+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:05:15.643+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:05:15.660+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.160 seconds
[2023-02-22T23:05:46.014+0000] {processor.py:153} INFO - Started process (PID=6529) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:05:46.018+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:05:46.023+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:05:46.022+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:05:46.077+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:05:46.150+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:05:46.149+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:05:46.225+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:05:46.225+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:05:46.230+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:05:46.230+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:05:46.235+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:05:46.234+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:05:46.277+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.300 seconds
[2023-02-22T23:06:16.392+0000] {processor.py:153} INFO - Started process (PID=6554) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:06:16.399+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:06:16.405+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:06:16.405+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:06:16.489+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:06:16.536+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:06:16.536+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:06:16.565+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:06:16.565+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:06:16.569+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:06:16.569+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:06:16.572+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:06:16.571+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:06:16.587+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.209 seconds
[2023-02-22T23:06:47.089+0000] {processor.py:153} INFO - Started process (PID=6591) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:06:47.096+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:06:47.099+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:06:47.099+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:06:47.179+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:06:47.290+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:06:47.289+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:06:47.360+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:06:47.360+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:06:47.369+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:06:47.368+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:06:47.373+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:06:47.373+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:06:47.405+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.322 seconds
[2023-02-22T23:07:17.549+0000] {processor.py:153} INFO - Started process (PID=6617) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:07:17.553+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:07:17.556+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:07:17.555+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:07:17.592+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:07:17.624+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:07:17.624+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:07:17.647+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:07:17.647+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:07:17.651+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:07:17.651+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:07:17.657+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:07:17.657+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:07:17.669+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.137 seconds
[2023-02-22T23:07:47.912+0000] {processor.py:153} INFO - Started process (PID=6654) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:07:47.924+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:07:47.925+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:07:47.925+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:07:47.957+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:07:47.991+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:07:47.991+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:07:48.018+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:07:48.018+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:07:48.022+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:07:48.022+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:07:48.029+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:07:48.029+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:07:48.042+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.136 seconds
[2023-02-22T23:08:18.413+0000] {processor.py:153} INFO - Started process (PID=6679) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:08:18.416+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:08:18.418+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:08:18.418+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:08:18.480+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:08:18.530+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:08:18.530+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:08:18.560+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:08:18.560+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:08:18.563+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:08:18.563+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:08:18.571+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:08:18.571+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:08:18.592+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.185 seconds
[2023-02-22T23:08:48.964+0000] {processor.py:153} INFO - Started process (PID=6717) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:08:48.969+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:08:48.972+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:08:48.972+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:08:49.109+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:08:49.336+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:08:49.335+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:08:49.378+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:08:49.378+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:08:49.383+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:08:49.383+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:08:49.401+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:08:49.400+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:08:49.436+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.513 seconds
[2023-02-22T23:09:20.088+0000] {processor.py:153} INFO - Started process (PID=6742) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:09:20.091+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:09:20.093+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:09:20.093+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:09:20.157+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:09:20.217+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:09:20.216+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:09:20.247+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:09:20.247+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:09:20.254+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:09:20.254+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:09:20.258+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:09:20.258+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:09:20.272+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.190 seconds
[2023-02-22T23:09:50.726+0000] {processor.py:153} INFO - Started process (PID=6780) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:09:50.731+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:09:50.736+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:09:50.736+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:09:50.825+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:09:50.897+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:09:50.897+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:09:50.940+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:09:50.939+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:09:50.945+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:09:50.945+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:09:50.952+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:09:50.952+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:09:50.984+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.270 seconds
[2023-02-22T23:10:21.420+0000] {processor.py:153} INFO - Started process (PID=6805) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:10:21.423+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:10:21.425+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:10:21.425+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:10:21.479+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:10:21.531+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:10:21.531+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:10:21.563+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:10:21.563+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:10:21.568+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:10:21.568+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:10:21.571+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:10:21.571+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:10:21.589+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.183 seconds
[2023-02-22T23:10:51.840+0000] {processor.py:153} INFO - Started process (PID=6842) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:10:51.845+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:10:51.853+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:10:51.851+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:10:51.932+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:10:52.022+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:10:52.021+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:10:52.062+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:10:52.062+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:10:52.067+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:10:52.067+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:10:52.070+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:10:52.070+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:10:52.094+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.267 seconds
[2023-02-22T23:11:22.222+0000] {processor.py:153} INFO - Started process (PID=6868) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:11:22.225+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:11:22.227+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:11:22.227+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:11:22.281+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:11:22.336+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:11:22.336+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:11:22.368+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:11:22.368+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:11:22.372+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:11:22.372+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:11:22.375+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:11:22.375+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:11:22.388+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.179 seconds
[2023-02-22T23:11:52.939+0000] {processor.py:153} INFO - Started process (PID=6906) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:11:52.970+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:11:52.977+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:11:52.977+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:11:53.062+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:11:53.154+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:11:53.154+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:11:53.207+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:11:53.207+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:11:53.214+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:11:53.214+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:11:53.222+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:11:53.222+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:11:53.245+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.335 seconds
[2023-02-22T23:12:23.533+0000] {processor.py:153} INFO - Started process (PID=6931) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:12:23.538+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:12:23.542+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:12:23.542+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:12:23.581+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:12:23.611+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:12:23.610+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:12:23.633+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:12:23.632+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:12:23.636+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:12:23.635+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:12:23.638+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:12:23.638+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:12:23.651+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.123 seconds
[2023-02-22T23:12:53.887+0000] {processor.py:153} INFO - Started process (PID=6969) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:12:53.897+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:12:53.901+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:12:53.900+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:12:53.956+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:12:54.006+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:12:54.005+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:12:54.042+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:12:54.042+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:12:54.047+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:12:54.047+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:12:54.052+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:12:54.051+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:12:54.076+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.207 seconds
[2023-02-22T23:13:24.290+0000] {processor.py:153} INFO - Started process (PID=6994) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:13:24.296+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:13:24.300+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:13:24.299+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:13:24.351+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:13:24.393+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:13:24.392+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:13:24.429+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:13:24.429+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:13:24.434+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:13:24.434+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:13:24.437+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:13:24.437+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:13:24.455+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.177 seconds
[2023-02-22T23:13:54.884+0000] {processor.py:153} INFO - Started process (PID=7031) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:13:54.891+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:13:54.897+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:13:54.896+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:13:54.988+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:13:55.056+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:13:55.056+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:13:55.080+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:13:55.080+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:13:55.087+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:13:55.087+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:13:55.092+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:13:55.092+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:13:55.107+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.232 seconds
[2023-02-22T23:14:25.406+0000] {processor.py:153} INFO - Started process (PID=7056) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:14:25.409+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:14:25.411+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:14:25.410+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:14:25.458+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:14:25.502+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:14:25.501+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:14:25.530+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:14:25.530+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:14:25.534+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:14:25.533+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:14:25.536+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:14:25.536+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:14:25.550+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.149 seconds
[2023-02-22T23:14:55.949+0000] {processor.py:153} INFO - Started process (PID=7094) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:14:55.953+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:14:55.955+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:14:55.955+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:14:56.008+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:14:56.092+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:14:56.091+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:14:56.209+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:14:56.209+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:14:56.217+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:14:56.217+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:14:56.223+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:14:56.223+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:14:56.262+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.321 seconds
[2023-02-22T23:15:26.713+0000] {processor.py:153} INFO - Started process (PID=7119) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:15:26.717+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:15:26.719+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:15:26.719+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:15:26.777+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:15:26.837+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:15:26.837+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:15:26.868+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:15:26.868+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:15:26.873+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:15:26.873+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:15:26.876+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:15:26.876+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:15:26.894+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.191 seconds
[2023-02-22T23:15:57.110+0000] {processor.py:153} INFO - Started process (PID=7153) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:15:57.113+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:15:57.115+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:15:57.115+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:15:57.195+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:15:57.247+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:15:57.245+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:15:57.283+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:15:57.283+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:15:57.288+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:15:57.288+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:15:57.293+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:15:57.293+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:15:57.316+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.212 seconds
[2023-02-22T23:16:27.587+0000] {processor.py:153} INFO - Started process (PID=7182) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:16:27.591+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:16:27.593+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:16:27.593+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:16:27.630+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:16:27.660+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:16:27.660+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:16:27.687+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:16:27.687+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:16:27.691+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:16:27.691+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:16:27.694+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:16:27.694+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:16:27.705+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.123 seconds
[2023-02-22T23:16:58.010+0000] {processor.py:153} INFO - Started process (PID=7218) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:16:58.015+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:16:58.020+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:16:58.019+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:16:58.072+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:16:58.141+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:16:58.140+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:16:58.179+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:16:58.179+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:16:58.190+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:16:58.190+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:16:58.196+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:16:58.195+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:16:58.218+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.213 seconds
[2023-02-22T23:17:28.405+0000] {processor.py:153} INFO - Started process (PID=7243) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:17:28.411+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:17:28.413+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:17:28.412+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:17:28.469+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:17:28.519+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:17:28.519+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:17:28.544+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:17:28.544+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:17:28.548+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:17:28.548+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:17:28.551+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:17:28.551+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:17:28.570+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.172 seconds
[2023-02-22T23:17:59.003+0000] {processor.py:153} INFO - Started process (PID=7281) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:17:59.006+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:17:59.008+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:17:59.008+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:17:59.106+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:17:59.141+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:17:59.141+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:17:59.168+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:17:59.168+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:17:59.172+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:17:59.172+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:17:59.177+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:17:59.175+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:17:59.192+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.198 seconds
[2023-02-22T23:18:29.371+0000] {processor.py:153} INFO - Started process (PID=7306) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:18:29.380+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:18:29.383+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:18:29.383+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:18:29.499+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:18:29.551+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:18:29.551+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:18:29.595+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:18:29.595+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:18:29.602+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:18:29.601+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:18:29.605+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:18:29.605+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:18:29.624+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.268 seconds
[2023-02-22T23:18:59.861+0000] {processor.py:153} INFO - Started process (PID=7344) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:18:59.863+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:18:59.864+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:18:59.864+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:18:59.903+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:18:59.939+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:18:59.939+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:18:59.968+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:18:59.968+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:18:59.972+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:18:59.972+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:18:59.974+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:18:59.974+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:18:59.987+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.129 seconds
[2023-02-22T23:19:30.273+0000] {processor.py:153} INFO - Started process (PID=7369) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:19:30.276+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:19:30.277+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:19:30.277+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:19:30.322+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:19:30.366+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:19:30.365+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:19:30.392+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:19:30.392+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:19:30.398+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:19:30.398+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:19:30.401+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:19:30.401+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:19:30.420+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.152 seconds
[2023-02-22T23:20:00.736+0000] {processor.py:153} INFO - Started process (PID=7406) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:20:00.741+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:20:00.743+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:20:00.743+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:20:00.788+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:20:00.826+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:20:00.826+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:20:00.850+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:20:00.850+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:20:00.855+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:20:00.855+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:20:00.858+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:20:00.858+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:20:00.870+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.138 seconds
[2023-02-22T23:20:31.228+0000] {processor.py:153} INFO - Started process (PID=7431) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:20:31.231+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:20:31.233+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:20:31.233+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:20:31.268+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:20:31.307+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:20:31.307+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:20:31.336+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:20:31.336+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:20:31.341+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:20:31.341+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:20:31.344+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:20:31.343+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:20:31.356+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.135 seconds
[2023-02-22T23:21:01.625+0000] {processor.py:153} INFO - Started process (PID=7468) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:21:01.635+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:21:01.643+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:21:01.642+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:21:01.700+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:21:01.771+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:21:01.770+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:21:01.901+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:21:01.900+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:21:01.926+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:21:01.926+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:21:01.935+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:21:01.935+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:21:01.982+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.370 seconds
[2023-02-22T23:21:32.413+0000] {processor.py:153} INFO - Started process (PID=7492) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:21:32.421+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:21:32.423+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:21:32.423+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:21:32.477+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:21:32.525+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:21:32.525+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:21:32.549+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:21:32.549+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:21:32.553+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:21:32.553+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:21:32.555+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:21:32.555+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:21:32.571+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.165 seconds
[2023-02-22T23:22:03.051+0000] {processor.py:153} INFO - Started process (PID=7530) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:22:03.057+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:22:03.082+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:22:03.081+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:22:03.152+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:22:03.231+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:22:03.231+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:22:03.284+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:22:03.284+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:22:03.290+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:22:03.290+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:22:03.293+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:22:03.293+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:22:03.327+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.285 seconds
[2023-02-22T23:22:33.640+0000] {processor.py:153} INFO - Started process (PID=7554) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:22:33.644+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:22:33.646+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:22:33.646+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:22:33.709+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:22:33.742+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:22:33.742+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:22:33.768+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:22:33.768+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:22:33.771+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:22:33.771+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:22:33.773+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:22:33.773+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:22:33.786+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.155 seconds
[2023-02-22T23:23:04.094+0000] {processor.py:153} INFO - Started process (PID=7591) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:23:04.097+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:23:04.099+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:23:04.098+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:23:04.129+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:23:04.159+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:23:04.158+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:23:04.178+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:23:04.178+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:23:04.182+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:23:04.182+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:23:04.184+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:23:04.184+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:23:04.201+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.114 seconds
[2023-02-22T23:23:34.464+0000] {processor.py:153} INFO - Started process (PID=7615) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:23:34.467+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:23:34.469+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:23:34.469+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:23:34.519+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:23:34.578+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:23:34.578+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:23:34.626+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:23:34.626+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:23:34.631+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:23:34.631+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:23:34.636+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:23:34.635+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:23:34.656+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.201 seconds
[2023-02-22T23:24:05.048+0000] {processor.py:153} INFO - Started process (PID=7652) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:24:05.051+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:24:05.054+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:24:05.053+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:24:05.107+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:24:05.147+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:24:05.146+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:24:05.169+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:24:05.169+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:24:05.173+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:24:05.173+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:24:05.175+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:24:05.175+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:24:05.187+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.145 seconds
[2023-02-22T23:24:35.504+0000] {processor.py:153} INFO - Started process (PID=7677) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:24:35.507+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:24:35.511+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:24:35.511+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:24:35.554+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:24:35.604+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:24:35.604+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:24:35.632+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:24:35.632+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:24:35.636+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:24:35.636+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:24:35.638+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:24:35.638+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:24:35.651+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.152 seconds
[2023-02-22T23:25:01.905+0000] {processor.py:153} INFO - Started process (PID=7711) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:25:01.908+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:25:01.914+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:25:01.913+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:25:02.751+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:25:02.962+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:25:02.962+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:25:03.017+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:25:03.017+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:25:03.028+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:25:03.028+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:25:03.032+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:25:03.032+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:25:03.090+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 1.195 seconds
[2023-02-22T23:25:33.415+0000] {processor.py:153} INFO - Started process (PID=7740) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:25:33.422+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:25:33.426+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:25:33.425+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:25:33.533+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:25:33.565+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:25:33.565+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:25:33.591+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:25:33.591+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:25:33.594+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:25:33.594+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:25:33.596+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:25:33.596+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:25:33.610+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.204 seconds
[2023-02-22T23:26:04.253+0000] {processor.py:153} INFO - Started process (PID=7766) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:26:04.256+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:26:04.258+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:26:04.258+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:26:04.392+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:26:04.433+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:26:04.433+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:26:04.459+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:26:04.458+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:26:04.462+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:26:04.462+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:26:04.465+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:26:04.465+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:26:04.477+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.237 seconds
[2023-02-22T23:26:34.703+0000] {processor.py:153} INFO - Started process (PID=7803) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:26:34.707+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:26:34.709+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:26:34.709+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:26:34.821+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:26:34.858+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:26:34.858+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:26:34.880+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:26:34.880+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:26:34.884+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:26:34.884+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:26:34.886+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:26:34.886+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:26:34.898+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.203 seconds
[2023-02-22T23:27:05.133+0000] {processor.py:153} INFO - Started process (PID=7828) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:27:05.136+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:27:05.138+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:27:05.138+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:27:05.233+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:27:05.267+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:27:05.267+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:27:05.288+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:27:05.288+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:27:05.292+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:27:05.291+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:27:05.295+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:27:05.294+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:27:05.316+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.189 seconds
[2023-02-22T23:27:35.579+0000] {processor.py:153} INFO - Started process (PID=7865) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:27:35.582+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:27:35.584+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:27:35.584+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:27:35.687+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:27:35.736+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:27:35.736+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:27:35.755+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:27:35.755+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:27:35.759+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:27:35.759+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:27:35.761+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:27:35.761+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:27:35.777+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.205 seconds
[2023-02-22T23:28:06.000+0000] {processor.py:153} INFO - Started process (PID=7900) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:28:06.004+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:28:06.007+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:28:06.007+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:28:06.101+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:28:06.138+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:28:06.137+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:28:06.185+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:28:06.184+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:28:06.189+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:28:06.189+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:28:06.192+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:28:06.192+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:28:06.212+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.217 seconds
[2023-02-22T23:28:36.433+0000] {processor.py:153} INFO - Started process (PID=7929) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:28:36.436+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:28:36.438+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:28:36.438+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:28:36.547+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:28:36.587+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:28:36.587+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:28:36.611+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:28:36.611+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:28:36.615+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:28:36.615+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:28:36.617+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:28:36.617+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:28:36.632+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.204 seconds
[2023-02-22T23:29:06.929+0000] {processor.py:153} INFO - Started process (PID=7966) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:29:06.933+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:29:06.935+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:29:06.934+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:29:07.067+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:29:07.126+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:29:07.126+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:29:07.170+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:29:07.170+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:29:07.175+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:29:07.175+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:29:07.178+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:29:07.178+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:29:07.199+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.280 seconds
[2023-02-22T23:29:25.167+0000] {processor.py:153} INFO - Started process (PID=7979) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:29:25.171+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:29:25.176+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:29:25.175+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:29:25.340+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:29:25.406+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:29:25.406+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:29:25.428+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:29:25.428+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:29:25.431+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:29:25.431+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:29:25.434+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:29:25.434+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:29:25.450+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.290 seconds
[2023-02-22T23:29:55.961+0000] {processor.py:153} INFO - Started process (PID=8016) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:29:55.965+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:29:55.967+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:29:55.967+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:29:56.088+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:29:56.126+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:29:56.126+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:29:56.153+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:29:56.153+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:29:56.157+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:29:56.157+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:29:56.160+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:29:56.160+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:29:56.176+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.221 seconds
[2023-02-22T23:30:26.365+0000] {processor.py:153} INFO - Started process (PID=8041) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:30:26.370+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:30:26.373+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:30:26.373+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:30:26.494+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:30:26.533+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:30:26.533+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:30:26.561+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:30:26.560+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:30:26.564+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:30:26.564+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:30:26.566+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:30:26.566+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:30:26.581+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.226 seconds
[2023-02-22T23:30:56.876+0000] {processor.py:153} INFO - Started process (PID=8078) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:30:56.878+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:30:56.881+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:30:56.881+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:30:56.976+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:30:57.022+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:30:57.022+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:30:57.057+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:30:57.057+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:30:57.071+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:30:57.071+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:30:57.077+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:30:57.077+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:30:57.105+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.233 seconds
[2023-02-22T23:31:27.209+0000] {processor.py:153} INFO - Started process (PID=8103) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:31:27.217+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:31:27.236+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:31:27.236+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:31:27.404+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:31:27.445+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:31:27.444+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:31:27.474+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:31:27.474+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:31:27.477+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:31:27.477+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:31:27.487+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:31:27.487+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:31:27.506+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.304 seconds
[2023-02-22T23:31:57.947+0000] {processor.py:153} INFO - Started process (PID=8140) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:31:57.957+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:31:57.960+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:31:57.960+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:31:58.082+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:31:58.113+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:31:58.112+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:31:58.132+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:31:58.132+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:31:58.135+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:31:58.135+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:31:58.141+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:31:58.141+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:31:58.153+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.216 seconds
[2023-02-22T23:32:28.352+0000] {processor.py:153} INFO - Started process (PID=8164) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:32:28.355+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:32:28.357+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:32:28.356+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:32:28.444+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:32:28.483+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:32:28.483+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:32:28.513+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:32:28.513+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:32:28.519+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:32:28.518+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:32:28.523+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:32:28.523+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:32:28.551+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.205 seconds
[2023-02-22T23:32:59.034+0000] {processor.py:153} INFO - Started process (PID=8201) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:32:59.038+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:32:59.051+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:32:59.051+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:32:59.166+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:32:59.419+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:32:59.418+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:32:59.470+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:32:59.470+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:32:59.477+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:32:59.477+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:32:59.480+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:32:59.480+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:32:59.513+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.488 seconds
[2023-02-22T23:33:13.251+0000] {processor.py:153} INFO - Started process (PID=8214) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:33:13.254+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:33:13.273+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:33:13.273+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:33:13.400+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:33:13.480+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:33:13.479+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:33:13.503+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:33:13.503+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:33:13.508+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:33:13.508+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:33:13.511+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:33:13.511+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:33:13.533+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.294 seconds
[2023-02-22T23:33:42.635+0000] {processor.py:153} INFO - Started process (PID=8240) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:33:42.638+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:33:42.639+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:33:42.639+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:33:42.759+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:33:42.834+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:33:42.832+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:33:42.870+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:33:42.870+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:33:42.878+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:33:42.878+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:33:42.882+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:33:42.882+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:33:42.901+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.273 seconds
[2023-02-22T23:34:13.587+0000] {processor.py:153} INFO - Started process (PID=8277) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:34:13.593+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:34:13.595+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:34:13.595+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:34:13.718+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:34:13.807+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:34:13.806+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:34:13.829+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:34:13.829+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:34:13.834+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:34:13.834+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:34:13.837+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:34:13.837+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:34:13.856+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.275 seconds
[2023-02-22T23:34:44.305+0000] {processor.py:153} INFO - Started process (PID=8304) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:34:44.307+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:34:44.310+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:34:44.309+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:34:44.415+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:34:44.455+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:34:44.454+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:34:44.483+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:34:44.483+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:34:44.487+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:34:44.487+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:34:44.489+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:34:44.489+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:34:44.505+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.207 seconds
[2023-02-22T23:35:14.778+0000] {processor.py:153} INFO - Started process (PID=8340) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:35:14.790+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:35:14.796+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:35:14.795+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:35:15.027+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:35:15.124+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:35:15.123+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:35:15.171+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:35:15.171+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:35:15.176+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:35:15.176+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:35:15.181+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:35:15.181+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:35:15.207+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.441 seconds
[2023-02-22T23:35:45.686+0000] {processor.py:153} INFO - Started process (PID=8366) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:35:45.689+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:35:45.691+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:35:45.691+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:35:45.804+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:35:45.851+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:35:45.850+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:35:45.879+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:35:45.879+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:35:45.883+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:35:45.883+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:35:45.885+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:35:45.885+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:35:45.900+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.225 seconds
[2023-02-22T23:36:16.140+0000] {processor.py:153} INFO - Started process (PID=8402) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:36:16.143+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:36:16.144+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:36:16.144+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:36:16.269+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:36:16.311+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:36:16.311+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:36:16.338+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:36:16.338+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:36:16.343+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:36:16.343+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:36:16.346+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:36:16.346+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:36:16.359+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.222 seconds
[2023-02-22T23:36:46.669+0000] {processor.py:153} INFO - Started process (PID=8426) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:36:46.674+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:36:46.677+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:36:46.677+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:36:46.792+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:36:46.838+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:36:46.838+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:36:46.868+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:36:46.867+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:36:46.871+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:36:46.871+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:36:46.876+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:36:46.876+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:36:46.890+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.226 seconds
[2023-02-22T23:37:04.073+0000] {processor.py:153} INFO - Started process (PID=8448) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:37:04.079+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:37:04.082+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:37:04.082+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:37:04.344+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:37:04.488+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:37:04.488+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:37:04.527+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:37:04.527+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:37:04.533+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:37:04.533+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:37:04.541+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:37:04.541+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:37:04.638+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.577 seconds
[2023-02-22T23:37:31.079+0000] {processor.py:153} INFO - Started process (PID=8476) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:37:31.082+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:37:31.084+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:37:31.084+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:37:31.252+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:37:31.310+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:37:31.309+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:37:31.340+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:37:31.340+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:37:31.344+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:37:31.343+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:37:31.347+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:37:31.347+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:37:31.378+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.310 seconds
[2023-02-22T23:38:01.875+0000] {processor.py:153} INFO - Started process (PID=8501) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:38:01.880+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:38:01.882+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:38:01.882+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:38:02.031+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:38:02.137+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:38:02.136+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:38:02.158+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:38:02.158+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:38:02.169+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:38:02.168+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:38:02.171+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:38:02.171+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:38:02.190+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.321 seconds
[2023-02-22T23:38:32.529+0000] {processor.py:153} INFO - Started process (PID=8538) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:38:32.532+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:38:32.533+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:38:32.533+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:38:32.653+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:38:32.691+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:38:32.691+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:38:32.720+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:38:32.720+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:38:32.723+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:38:32.723+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:38:32.726+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:38:32.726+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:38:32.739+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.218 seconds
[2023-02-22T23:39:02.923+0000] {processor.py:153} INFO - Started process (PID=8562) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:39:02.925+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:39:02.927+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:39:02.927+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:39:03.023+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:39:03.066+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:39:03.066+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:39:03.095+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:39:03.095+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:39:03.098+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:39:03.098+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:39:03.101+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:39:03.101+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:39:03.112+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.193 seconds
[2023-02-22T23:39:33.604+0000] {processor.py:153} INFO - Started process (PID=8599) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:39:33.610+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:39:33.612+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:39:33.612+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:39:33.728+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:39:33.759+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:39:33.759+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:39:33.783+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:39:33.783+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:39:33.793+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:39:33.793+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:39:33.795+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:39:33.795+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:39:33.807+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.209 seconds
[2023-02-22T23:40:04.104+0000] {processor.py:153} INFO - Started process (PID=8624) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:40:04.108+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:40:04.109+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:40:04.109+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:40:04.226+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:40:04.267+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:40:04.267+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:40:04.292+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:40:04.292+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:40:04.296+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:40:04.296+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:40:04.299+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:40:04.299+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:40:04.329+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.234 seconds
[2023-02-22T23:40:10.211+0000] {processor.py:153} INFO - Started process (PID=8637) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:40:10.213+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:40:10.215+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:40:10.215+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:40:10.401+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:40:10.465+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:40:10.464+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:40:10.485+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:40:10.485+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:40:10.489+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:40:10.488+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:40:10.495+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:40:10.495+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:40:10.511+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.304 seconds
[2023-02-22T23:40:40.978+0000] {processor.py:153} INFO - Started process (PID=8669) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:40:40.981+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:40:40.987+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:40:40.987+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:40:41.090+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:40:41.140+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:40:41.140+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:40:41.172+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:40:41.172+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:40:41.179+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:40:41.179+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:40:41.186+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:40:41.186+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:40:41.201+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.229 seconds
[2023-02-22T23:41:11.326+0000] {processor.py:153} INFO - Started process (PID=8699) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:41:11.331+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:41:11.333+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:41:11.333+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:41:11.436+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:41:11.473+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:41:11.472+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:41:11.492+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:41:11.492+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:41:11.495+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:41:11.495+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:41:11.503+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:41:11.503+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:41:11.517+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.198 seconds
[2023-02-22T23:41:42.094+0000] {processor.py:153} INFO - Started process (PID=8733) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:41:42.108+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:41:42.116+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:41:42.116+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:41:42.375+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:41:42.450+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:41:42.449+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:41:42.509+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:41:42.509+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:41:42.519+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:41:42.519+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:41:42.526+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:41:42.525+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:41:42.558+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.504 seconds
[2023-02-22T23:42:13.390+0000] {processor.py:153} INFO - Started process (PID=8760) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:42:13.393+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:42:13.395+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:42:13.394+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:42:13.511+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:42:13.561+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:42:13.561+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:42:13.598+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:42:13.598+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:42:13.602+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:42:13.602+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:42:13.605+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:42:13.605+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:42:13.619+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.235 seconds
[2023-02-22T23:42:44.007+0000] {processor.py:153} INFO - Started process (PID=8785) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:42:44.009+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:42:44.014+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:42:44.014+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:42:44.139+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:42:44.193+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:42:44.193+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:42:44.234+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:42:44.234+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:42:44.241+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:42:44.241+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:42:44.244+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:42:44.244+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:42:44.260+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.258 seconds
[2023-02-22T23:43:14.500+0000] {processor.py:153} INFO - Started process (PID=8823) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:43:14.509+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:43:14.512+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:14.512+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:43:14.613+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:43:14.647+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:14.647+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:43:14.671+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:14.671+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:43:14.676+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:14.676+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:43:14.679+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:14.679+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:43:14.693+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.198 seconds
[2023-02-22T23:43:45.305+0000] {processor.py:153} INFO - Started process (PID=8848) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:43:45.309+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:43:45.311+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:45.311+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:43:45.483+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:43:45.539+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:45.539+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:43:45.570+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:45.570+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:43:45.574+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:45.574+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:43:45.577+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:45.577+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:43:45.594+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.294 seconds
[2023-02-22T23:43:52.449+0000] {processor.py:153} INFO - Started process (PID=8861) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:43:52.452+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:43:52.455+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:52.455+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:43:52.580+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:43:52.633+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:52.632+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:43:52.675+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:52.675+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:43:52.679+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:52.679+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:43:52.699+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:52.698+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:43:52.716+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.277 seconds
[2023-02-22T23:43:55.808+0000] {processor.py:153} INFO - Started process (PID=8862) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:43:55.810+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:43:55.811+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:55.811+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:43:55.952+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:43:56.014+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:56.013+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:43:56.066+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:56.066+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:43:56.078+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:56.078+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:43:56.081+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:56.081+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:43:56.110+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.311 seconds
[2023-02-22T23:43:57.195+0000] {processor.py:153} INFO - Started process (PID=8863) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:43:57.200+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:43:57.202+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:57.202+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:43:57.330+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:43:57.390+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:57.389+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:43:57.419+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:57.419+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:43:57.422+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:57.422+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:43:57.424+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:57.424+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:43:57.440+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.253 seconds
[2023-02-22T23:43:58.218+0000] {processor.py:153} INFO - Started process (PID=8864) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:43:58.219+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:43:58.227+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:58.227+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:43:58.327+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:43:58.371+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:58.370+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:43:58.398+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:58.398+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:43:58.402+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:58.402+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:43:58.405+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:43:58.405+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:43:58.422+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.208 seconds
[2023-02-22T23:44:28.857+0000] {processor.py:153} INFO - Started process (PID=8900) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:44:28.872+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:44:28.874+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:44:28.873+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:44:29.026+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:44:29.100+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:44:29.097+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:44:29.131+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:44:29.130+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:44:29.149+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:44:29.148+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:44:29.151+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:44:29.151+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:44:29.188+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.338 seconds
[2023-02-22T23:44:59.584+0000] {processor.py:153} INFO - Started process (PID=8924) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:44:59.587+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:44:59.589+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:44:59.589+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:44:59.683+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:44:59.737+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:44:59.737+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:44:59.767+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:44:59.767+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:44:59.771+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:44:59.771+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:44:59.774+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:44:59.774+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:44:59.787+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.208 seconds
[2023-02-22T23:45:29.990+0000] {processor.py:153} INFO - Started process (PID=8961) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:45:29.994+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:45:29.995+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:45:29.995+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:45:30.119+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:45:30.189+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:45:30.189+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:45:30.219+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:45:30.219+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:45:30.223+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:45:30.223+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:45:30.226+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:45:30.226+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:45:30.245+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.260 seconds
[2023-02-22T23:46:00.434+0000] {processor.py:153} INFO - Started process (PID=8995) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:46:00.439+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:46:00.441+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:46:00.441+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:46:00.578+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:46:00.647+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:46:00.647+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:46:00.771+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:46:00.771+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:46:00.780+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:46:00.780+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:46:00.783+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:46:00.783+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:46:00.806+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.381 seconds
[2023-02-22T23:46:31.062+0000] {processor.py:153} INFO - Started process (PID=9023) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:46:31.070+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:46:31.072+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:46:31.072+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:46:31.209+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:46:31.266+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:46:31.266+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:46:31.307+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:46:31.307+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:46:31.313+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:46:31.313+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:46:31.318+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:46:31.318+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:46:31.341+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.290 seconds
[2023-02-22T23:47:01.535+0000] {processor.py:153} INFO - Started process (PID=9060) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:47:01.541+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:47:01.546+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:47:01.546+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:47:01.703+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:47:01.796+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:47:01.795+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:47:01.857+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:47:01.857+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:47:01.863+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:47:01.863+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:47:01.868+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:47:01.868+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:47:01.892+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.369 seconds
[2023-02-22T23:47:32.218+0000] {processor.py:153} INFO - Started process (PID=9085) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:47:32.221+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:47:32.223+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:47:32.223+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:47:32.306+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:47:32.350+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:47:32.350+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:47:32.369+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:47:32.369+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:47:32.372+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:47:32.372+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:47:32.374+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:47:32.374+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:47:32.390+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.177 seconds
[2023-02-22T23:47:48.421+0000] {processor.py:153} INFO - Started process (PID=9106) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:47:48.424+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:47:48.426+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:47:48.426+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:47:48.563+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:47:48.660+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:47:48.660+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:47:48.718+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:47:48.718+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:47:48.733+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:47:48.733+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:47:48.741+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:47:48.741+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:47:48.767+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.356 seconds
[2023-02-22T23:48:19.075+0000] {processor.py:153} INFO - Started process (PID=9133) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:48:19.078+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:48:19.080+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:48:19.079+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:48:19.218+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:48:19.269+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:48:19.269+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:48:19.301+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:48:19.301+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:48:19.309+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:48:19.309+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:48:19.312+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:48:19.312+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:48:19.327+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.258 seconds
[2023-02-22T23:48:49.472+0000] {processor.py:153} INFO - Started process (PID=9170) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:48:49.478+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:48:49.483+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:48:49.482+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:48:49.670+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:48:49.745+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:48:49.745+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:48:49.785+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:48:49.785+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:48:49.800+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:48:49.800+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:48:49.807+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:48:49.807+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:48:49.839+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.379 seconds
[2023-02-22T23:48:58.858+0000] {processor.py:153} INFO - Started process (PID=9171) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:48:58.863+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:48:58.866+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:48:58.866+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:48:59.072+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:48:59.134+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:48:59.133+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:48:59.171+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:48:59.171+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:48:59.175+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:48:59.175+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:48:59.178+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:48:59.178+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:48:59.197+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.348 seconds
[2023-02-22T23:49:29.860+0000] {processor.py:153} INFO - Started process (PID=9209) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:49:29.862+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:49:29.864+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:49:29.864+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:49:29.954+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:49:29.986+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:49:29.985+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:49:30.031+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:49:30.030+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:49:30.037+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:49:30.037+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:49:30.041+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:49:30.041+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:49:30.061+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.208 seconds
[2023-02-22T23:50:00.391+0000] {processor.py:153} INFO - Started process (PID=9234) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:50:00.393+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:50:00.395+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:50:00.395+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:50:00.529+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:50:00.580+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:50:00.579+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:50:00.612+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:50:00.612+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:50:00.615+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:50:00.615+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:50:00.618+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:50:00.618+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:50:00.632+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.248 seconds
[2023-02-22T23:50:30.925+0000] {processor.py:153} INFO - Started process (PID=9271) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:50:30.945+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:50:30.952+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:50:30.952+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:50:31.124+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:50:31.199+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:50:31.198+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:50:31.231+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:50:31.231+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:50:31.235+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:50:31.235+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:50:31.238+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:50:31.238+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:50:31.264+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.353 seconds
[2023-02-22T23:51:01.442+0000] {processor.py:153} INFO - Started process (PID=9296) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:51:01.445+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:51:01.447+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:51:01.447+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:51:01.558+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:51:01.611+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:51:01.610+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:51:01.644+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:51:01.644+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:51:01.649+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:51:01.649+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:51:01.652+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:51:01.652+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:51:01.666+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.236 seconds
[2023-02-22T23:51:31.978+0000] {processor.py:153} INFO - Started process (PID=9333) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:51:31.983+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:51:31.987+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:51:31.986+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:51:32.122+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:51:32.164+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:51:32.164+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:51:32.187+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:51:32.187+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:51:32.191+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:51:32.191+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:51:32.193+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:51:32.193+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:51:32.205+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.233 seconds
[2023-02-22T23:52:02.455+0000] {processor.py:153} INFO - Started process (PID=9358) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:52:02.458+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:52:02.459+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:52:02.459+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:52:02.605+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:52:02.654+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:52:02.654+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:52:02.684+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:52:02.684+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:52:02.688+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:52:02.688+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:52:02.691+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:52:02.691+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:52:02.708+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.257 seconds
[2023-02-22T23:52:32.883+0000] {processor.py:153} INFO - Started process (PID=9395) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:52:32.887+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:52:32.890+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:52:32.889+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:52:33.017+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:52:33.054+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:52:33.054+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:52:33.076+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:52:33.076+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:52:33.079+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:52:33.079+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:52:33.082+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:52:33.082+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:52:33.097+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.223 seconds
[2023-02-22T23:53:03.394+0000] {processor.py:153} INFO - Started process (PID=9420) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:53:03.399+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:53:03.401+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:53:03.400+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:53:03.526+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:53:03.579+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:53:03.579+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:53:03.608+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:53:03.608+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:53:03.613+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:53:03.613+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:53:03.615+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:53:03.615+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:53:03.628+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.241 seconds
[2023-02-22T23:53:33.836+0000] {processor.py:153} INFO - Started process (PID=9457) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:53:33.839+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:53:33.841+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:53:33.841+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:53:33.951+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:53:33.987+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:53:33.987+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:53:34.008+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:53:34.008+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:53:34.011+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:53:34.011+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:53:34.013+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:53:34.013+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:53:34.031+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.203 seconds
[2023-02-22T23:54:02.304+0000] {processor.py:153} INFO - Started process (PID=9481) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:54:02.307+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:54:02.311+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:54:02.311+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:54:02.422+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'populate_db', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:54:02.511+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:54:02.510+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:54:02.536+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:54:02.535+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:54:02.540+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:54:02.540+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:54:02.542+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:54:02.542+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:54:02.563+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.281 seconds
[2023-02-22T23:54:32.941+0000] {processor.py:153} INFO - Started process (PID=9519) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:54:32.944+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:54:32.945+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:54:32.945+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:54:33.055+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:54:33.089+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:54:33.089+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:54:33.115+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:54:33.115+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:54:33.119+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:54:33.119+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:54:33.121+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:54:33.121+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:54:33.137+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.203 seconds
[2023-02-22T23:55:03.389+0000] {processor.py:153} INFO - Started process (PID=9544) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:55:03.394+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:55:03.396+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:03.396+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:55:03.528+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:55:03.578+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:03.578+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:55:03.608+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:03.608+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:55:03.613+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:03.613+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:55:03.616+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:03.616+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:55:03.635+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.255 seconds
[2023-02-22T23:55:12.595+0000] {processor.py:153} INFO - Started process (PID=9557) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:55:12.599+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:55:12.600+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:12.600+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:55:12.708+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:55:12.795+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:12.795+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:55:12.819+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:12.818+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:55:12.823+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:12.823+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:55:12.827+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:12.827+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:55:12.852+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.267 seconds
[2023-02-22T23:55:13.809+0000] {processor.py:153} INFO - Started process (PID=9558) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:55:13.811+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:55:13.813+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:13.813+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:55:13.919+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:55:13.950+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:13.950+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:55:13.967+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:13.967+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:55:13.971+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:13.970+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:55:13.977+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:13.977+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:55:13.991+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.187 seconds
[2023-02-22T23:55:44.503+0000] {processor.py:153} INFO - Started process (PID=9592) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:55:44.507+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:55:44.509+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:44.509+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:55:44.631+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:55:44.681+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:44.681+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:55:44.713+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:44.713+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:55:44.717+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:44.717+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:55:44.720+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:44.720+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:55:44.736+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.240 seconds
[2023-02-22T23:55:57.787+0000] {processor.py:153} INFO - Started process (PID=9608) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:55:57.792+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:55:57.818+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:57.804+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:55:58.145+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:55:58.286+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:58.284+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:55:58.331+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:58.331+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:55:58.346+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:58.345+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:55:58.352+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:55:58.352+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:55:58.407+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.646 seconds
[2023-02-22T23:56:28.993+0000] {processor.py:153} INFO - Started process (PID=9633) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:56:28.999+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:56:29.001+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:56:29.001+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:56:29.135+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:56:29.187+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:56:29.187+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:56:29.218+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:56:29.218+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:56:29.222+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:56:29.222+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:56:29.226+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:56:29.226+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:56:29.260+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.276 seconds
[2023-02-22T23:56:59.848+0000] {processor.py:153} INFO - Started process (PID=9669) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:56:59.852+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:56:59.854+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:56:59.854+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:57:00.122+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:57:00.200+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:57:00.200+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:57:00.245+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:57:00.245+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:57:00.252+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:57:00.252+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:57:00.260+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:57:00.260+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:57:00.291+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.451 seconds
[2023-02-22T23:57:30.730+0000] {processor.py:153} INFO - Started process (PID=9694) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:57:30.736+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:57:30.739+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:57:30.738+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:57:30.857+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:57:30.897+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:57:30.897+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:57:30.924+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:57:30.924+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:57:30.928+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:57:30.928+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:57:30.931+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:57:30.931+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:57:30.945+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.229 seconds
[2023-02-22T23:58:01.112+0000] {processor.py:153} INFO - Started process (PID=9730) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:58:01.116+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:58:01.118+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:58:01.117+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:58:01.232+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:58:01.293+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:58:01.293+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:58:01.328+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:58:01.328+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:58:01.332+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:58:01.332+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:58:01.335+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:58:01.334+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:58:01.348+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.246 seconds
[2023-02-22T23:58:05.656+0000] {processor.py:153} INFO - Started process (PID=9731) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:58:05.664+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:58:05.672+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:58:05.672+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:58:05.824+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'db_to_csv', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:58:05.962+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:58:05.962+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:58:05.989+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:58:05.989+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:58:05.993+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:58:05.993+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:58:05.996+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:58:05.996+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:58:06.019+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.377 seconds
[2023-02-22T23:58:36.772+0000] {processor.py:153} INFO - Started process (PID=9765) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:58:36.775+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:58:36.777+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:58:36.776+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:58:36.943+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'populate_db', 'scrap_metadata']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:58:36.996+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:58:36.995+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:58:37.031+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:58:37.031+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:58:37.036+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:58:37.035+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:58:37.039+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:58:37.039+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:58:37.061+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.292 seconds
[2023-02-22T23:59:07.200+0000] {processor.py:153} INFO - Started process (PID=9794) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:59:07.203+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:59:07.207+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:59:07.205+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:59:07.320+0000] {processor.py:753} INFO - DAG(s) dict_keys(['scrap_metadata', 'db_to_csv', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:59:07.370+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:59:07.370+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:59:07.401+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:59:07.401+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:59:07.405+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:59:07.405+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:59:07.409+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:59:07.408+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:59:07.426+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.232 seconds
[2023-02-22T23:59:14.442+0000] {processor.py:153} INFO - Started process (PID=9807) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:59:14.444+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:59:14.446+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:59:14.446+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:59:14.557+0000] {processor.py:753} INFO - DAG(s) dict_keys(['populate_db', 'scrap_metadata', 'db_to_csv']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:59:14.621+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:59:14.621+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:59:14.643+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:59:14.643+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:59:14.646+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:59:14.646+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:59:14.649+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:59:14.648+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:59:14.663+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.232 seconds
[2023-02-22T23:59:44.871+0000] {processor.py:153} INFO - Started process (PID=9831) to work on /opt/airflow/dags/schedule.py
[2023-02-22T23:59:44.873+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/schedule.py for tasks to queue
[2023-02-22T23:59:44.875+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:59:44.875+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/schedule.py
[2023-02-22T23:59:44.964+0000] {processor.py:753} INFO - DAG(s) dict_keys(['db_to_csv', 'scrap_metadata', 'populate_db']) retrieved from /opt/airflow/dags/schedule.py
[2023-02-22T23:59:44.993+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:59:44.993+0000] {dag.py:2690} INFO - Sync 3 DAGs
[2023-02-22T23:59:45.016+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:59:45.016+0000] {dag.py:3441} INFO - Setting next_dagrun for db_to_csv to None, run_after=None
[2023-02-22T23:59:45.020+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:59:45.020+0000] {dag.py:3441} INFO - Setting next_dagrun for populate_db to None, run_after=None
[2023-02-22T23:59:45.022+0000] {logging_mixin.py:137} INFO - [2023-02-22T23:59:45.022+0000] {dag.py:3441} INFO - Setting next_dagrun for scrap_metadata to 2023-02-22T00:00:00+00:00, run_after=2023-02-23T00:00:00+00:00
[2023-02-22T23:59:45.033+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/schedule.py took 0.168 seconds
